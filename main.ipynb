{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SchmetterlingIII/D.T./blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0617d7",
      "metadata": {
        "id": "4a0617d7"
      },
      "source": [
        "This is an improvement from the initial `spline-interp.ipynb` with a focus on a clearer preceding pseudocode as well as code structure, with classes and helper functions being developed first. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34b1ae3",
      "metadata": {},
      "source": [
        "### Extensions\n",
        "I have completed a current proof-of-concept/MVP but overtime I would still like to iterate on this to understand how to more accurately read in data from multiple channels, handle calculations (especially torsion and 3D twisting in an abstract sense) and the user interface for this design as I hope to expand this project with more integrated devices (such as the graphene-based sensors from `e-body Labs` in the `Dyson School of Design Engineering, Imperial College London`) and would like my basis to be strong to bring things to the team. \n",
        "\n",
        "**Technical**\n",
        "\n",
        "*These should also be approached mathematically - and a writeup to be included here - as it is good to understand the reasons why something is implemented*\n",
        "\n",
        "- Quaternions \n",
        "- Kalman filtering \n",
        "- SQLite data storage\n",
        "- ML for data interpretation\n",
        "    - allowing for more personalised data in the calibration phase and can later allow for inferences of chronic pain/appropriate stretches for this\n",
        "- Torsion ($\\tau$) rather than curvature ($\\kappa$) in order to extract more data (since it is a 3D representation of how a function curves)\n",
        "\n",
        "**User Experience**\n",
        "\n",
        "*Will also be quite technical, but informed by feedback from physiotherapists, current researchers and orthopaedic practictioners*\n",
        "\n",
        "- Exporting all data to a database where a more personalised statistical interpretation of the data takes place\n",
        "- A report from this personalised data\n",
        "- A more comprehensive calibration phase (where users have to maintain certain poses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QDfnx1Jctl7S",
      "metadata": {
        "id": "QDfnx1Jctl7S"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1O7O-U3EuSQy",
      "metadata": {
        "id": "1O7O-U3EuSQy"
      },
      "source": [
        "### Module Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64AcUw_StsXs",
      "metadata": {
        "id": "64AcUw_StsXs"
      },
      "outputs": [],
      "source": [
        "import serial.tools.list_ports\n",
        "import string\n",
        "import serial\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from  mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "import scipy\n",
        "import sys # specifically for debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9On7yIm_trSN",
      "metadata": {
        "id": "9On7yIm_trSN"
      },
      "source": [
        "### Serial Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7LDtVg4GuW3g",
      "metadata": {
        "id": "7LDtVg4GuW3g"
      },
      "outputs": [],
      "source": [
        "BAUDRATE = 115200\n",
        "try:\n",
        "    '''\n",
        "    Basic setup for port communication\n",
        "    '''\n",
        "\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    serialInst = serial.Serial()\n",
        "    portList = [str(i) for i in ports]\n",
        "    print(portList)\n",
        "\n",
        "    com = input(\"Select COM PORT for Arduino: \")\n",
        "\n",
        "    for i in range(len(portList)):\n",
        "        if portList[i].startswith(\"COM\" + str(com)):\n",
        "            SERIAL_PORT = \"COM\" + str(com)\n",
        "            print(SERIAL_PORT)\n",
        "\n",
        "    serialInst.baudrate = BAUDRATE\n",
        "    serialInst.port = SERIAL_PORT\n",
        "    serialInst.open()\n",
        "    print(f\"Connected to {SERIAL_PORT} at {BAUDRATE} baud.\")\n",
        "\n",
        "    '''\n",
        "    Initial data initialisation.\n",
        "    This is a complementary function to the c++ code which says how many sensors are connected and which positions they are in.\n",
        "    '''\n",
        "    while True:\n",
        "        line = serialInst.readline().decode('utf-8') # each line is the decoded form of the serial\n",
        "        if line: # if there is data in the readline i.e if line == True\n",
        "            print(f\"Arduino: {line}\")\n",
        "        if \"Available channels: \" in line:\n",
        "            channels_part = line.split(\":\")[-1].strip() # extract all data after colon\n",
        "            # parse the csv into on stringed list\n",
        "            IMU_ID_LIST = [id.strip() for id in channels_part.split(\",\") if id.strip()]\n",
        "        if \"Number of sensors: \" in line:\n",
        "           ID_NUM = int(line.strip(\":\")[-3]) # the number of read sensors, last instance is \"\\n\" and so index = -3 is the appropriate index\n",
        "           IMU_DEQUES = [deque(maxlen=50) for i in range(ID_NUM)]\n",
        "        if \"Waiting for 'begin program' command\" in line:\n",
        "            break\n",
        "\n",
        "    '''\n",
        "    Input of linear distances for the forward kinematics chain (and subsequent calculations)\n",
        "    '''\n",
        "    print(\"INSTRUCTIONS:\\nInput the linear distances between your sensors in metres.\\nMeasure from lowest to highest.\\nI would recommend using a high resolution ruler to reduce drift.\\n\")\n",
        "    linear_distances = []\n",
        "    for i in range(ID_NUM - 1):\n",
        "        value = float(input(f\"{i + 1}: \"))\n",
        "        linear_distances.append(value)\n",
        "\n",
        "    print(\"Sending 'begin' command to Arduino\")\n",
        "    serialInst.write(b'begin program') # sent in bytes rather than a high level string since it is sent to back to the compiler\n",
        "\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TV9aw1p7xnT-",
      "metadata": {
        "id": "TV9aw1p7xnT-"
      },
      "source": [
        "### Helper Functions\n",
        "- data filtering (madgwick filter)\n",
        "- forward kinematics function\n",
        "- cubic spline (outputting discretised function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TWzkjXb0yn4S",
      "metadata": {
        "id": "TWzkjXb0yn4S"
      },
      "outputs": [],
      "source": [
        "def angle_tilt_filter(IMU_data, dt):\n",
        "    '''\n",
        "    https://www.youtube.com/watch?v=7VW_XVbtu9k\n",
        "    Use the above video to extract the angle between each of the IMUs.\n",
        "\n",
        "    This is less susceptible to gyro tilt over time\n",
        "\n",
        "    Return: normalised matrix containing the vector values of each of the filtered IMUs using this angle extraction method.\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    each data is streamed one at a time.\n",
        "    find the local pitch and yaw\n",
        "    from these angles, get the appropriate direction vector\n",
        "    store into the matrix\n",
        "\n",
        "    return np.array([(), (), (), ..., ()])\n",
        "    '''\n",
        "    ax, ay, az, gyro_x, gyro_y, gyro_z = IMU_data\n",
        "\n",
        "    accel_angle_x = np.arctan2(ay, az) # about the x-axis\n",
        "    accel_angle_y = np.arctan2(ax, az) # about the y-axis\n",
        "\n",
        "    gyro_x += gyro_x * dt\n",
        "    gyro_y += gyro_y * dt\n",
        "\n",
        "    # rather than a filter yet, I will just have a bias towards angular tilt\n",
        "    # these numbers are arbitrary (copied from the video) but I will move onto Kalman filtering later\n",
        "    fused_angle_x = 0.98 * (gyro_x) + 0.02 * accel_angle_x # roll\n",
        "    fused_angle_y = 0.98 * (gyro_y) + 0.02 * accel_angle_y # pitch\n",
        "\n",
        "    normal, y_direction = angles_to_direction_vector(fused_angle_x, fused_angle_y)\n",
        "\n",
        "    return normal, y_direction\n",
        "\n",
        "def angles_to_direction_vector(roll, pitch):\n",
        "    '''\n",
        "    Calculates normal vector and direction vector in direction of y-axis.\n",
        "\n",
        "    The y-axis direction vector will be used for the forward kinematics; the normal vector will reinforce calculations of curvature (and be the precursor to having a 3D understanding of curvature along the spine).\n",
        "    '''\n",
        "    # normal\n",
        "    normal = np.array([\n",
        "        np.sin(pitch) * np.cos(roll),\n",
        "        -np.sin(roll),\n",
        "        np.cos(roll) * np.cos(pitch)\n",
        "    ])\n",
        "\n",
        "    # y direction\n",
        "    y_direction = np.array([\n",
        "        np.sin(pitch) * np.sin(roll),\n",
        "        np.cos(roll),\n",
        "        np.cos(pitch) * np.sin(roll)\n",
        "    ])\n",
        "\n",
        "    normal = normal / np.linalg.norm(normal)\n",
        "    y_direction = y_direction / np.linalg.norm(y_direction)\n",
        "\n",
        "    return normal, y_direction\n",
        "\n",
        "def kalman_filter(angle_filtered_data):\n",
        "    '''\n",
        "    https://www.youtube.com/watch?v=5HuN9iL-zxU&list=PLeuMA6tJBPKsAfRfFuGrEljpBow5hPVD4&index=18\n",
        "    Another tutorial that will help me actually have an accurate input of the data, without resorting to l'IA or learning the maths behind this.\n",
        "\n",
        "    I will look into how Kalman filters work from a high level but if there is a python module for it then I will be happy to just copy it.\n",
        "    '''\n",
        "    return filtered_data\n",
        "\n",
        "def forward_kinematics(filtered_data, linear_distances):\n",
        "    '''\n",
        "    Computes positions using the IMU data and distances, assuming that the base IMU is at the origin.\n",
        "    Returns: list of 3D positions where the IMUs are in an arbitrary & scaled 3D space\n",
        "\n",
        "    For later improvements, I will use quaternions to handle the tilt as done in the CHARM Lab device.\n",
        "    '''\n",
        "\n",
        "    # if no data, return nothing important (in the same format which can be unpacked but not causing a crash)\n",
        "    if not filtered_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    origin = np.array([0,0,0])\n",
        "    p_n = [origin]\n",
        "    cumulative_distance = 0\n",
        "    t_values = [0]\n",
        "\n",
        "    for i in range(len(filtered_data)):\n",
        "        v_n = filtered_data[i] # the direction vector at this point\n",
        "        l_n = linear_distances[i] if i != (len(filtered_data) - 1) else 0.1 # the scalar distance between the upcoming sensor and the current\n",
        "        # I have added the 0.1 since the final IMU will not have a subsequent sensor to work towards so this tilt will approximate what's happening up to the neck area\n",
        "\n",
        "        p_n_plus_1 = p_n[-1] + (v_n * l_n) # the next position vector along the chain\n",
        "        p_n.append(p_n_plus_1)\n",
        "\n",
        "        cumulative_distance += l_n\n",
        "        t_values.append(cumulative_distance)\n",
        "\n",
        "    return p_n, t_values # returns vector position & t_values for interpolation\n",
        "\n",
        "def cubic_spline_interpolation(IMU_positions, t_values):\n",
        "    '''\n",
        "    Interpolates the function using the formed kinematic chain in a parametrised format.\n",
        "\n",
        "    Returns the plotting values\n",
        "    '''\n",
        "    x = IMU_positions[:, 0]\n",
        "    y = IMU_positions[:, 1]\n",
        "    z = IMU_positions[:, 2]\n",
        "\n",
        "    xc = CubicSpline(t_values, x)\n",
        "    yc = CubicSpline(t_values, y)\n",
        "    zc = CubicSpline(t_values, z)\n",
        "\n",
        "    # this variable stores the t_values that are along this interpolated spline in a discrete package i.e. \"plotting_t_values\"\n",
        "    discrete_points = 250\n",
        "    plot_t = np.linspace(min(t_values), max(t_values), discrete_points)\n",
        "\n",
        "    return xc, yc, zc, plot_t\n",
        "\n",
        "def curvature_list(plot_t):\n",
        "    '''\n",
        "    This function returns an array of scalar curvatures for each point on the interpolated spline function.\n",
        "\n",
        "    The issue with this (for future reference) is that these points only show a scalar and so improvements of this could be to interpolate the normal values of the vectors along the function to have a better understanding of curvature in 3D space.\n",
        "    '''\n",
        "    r = (xc(plot_t, 0), yc(plot_t, 0), zc(plot_t, 0))\n",
        "    r_prime = (xc(plot_t, 1), yc(plot_t, 1), zc(plot_t, 1))\n",
        "    r_double_prime = (xc(plot_t, 2), yc(plot_t, 2), zc(plot_t, 2))\n",
        "\n",
        "    kappa = (np.linalg.norm(np.cross(r_prime, r_double_prime)))/(np.linalg.norm(r_prime)**3)\n",
        "    return kappa # an array of scalar values for the curvature along this interpolated spline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sRlJb16lQGth",
      "metadata": {
        "id": "sRlJb16lQGth"
      },
      "source": [
        "### IMU Class\n",
        "This just holds the state for each of the IMUs (their direction vectors) and the `dt` for each of it. Further, it will hold how filtered the data is as a quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r9i6WIeBQ5Jr",
      "metadata": {
        "id": "r9i6WIeBQ5Jr"
      },
      "outputs": [],
      "source": [
        "class IMU_data:\n",
        "    def __init__(self):\n",
        "        self.direction_vector = None\n",
        "        self.time = time.time() # used for calculating the `dt` of the sensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stFde0UOEZ1q",
      "metadata": {
        "id": "stFde0UOEZ1q"
      },
      "source": [
        "### Spine Analysis Class\n",
        "This is the class that effectively analyses the instance of the curvature and, by comparing this instance with the distribution of curvatures stored during the calibration mode, outputs whether there is (a) a deviation from \"good\" posture* or (b) prolonged static posture.\n",
        "\n",
        "*The feeback mechanism of this is inherently flawed given there shows diminishing links to this effect. However, working towards the distribution is still a good reason to learn ML (and with enough data, this awareness and deviation from \"current posture\" will help to inform more complex decisions of when alerts should go off)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828c06f4",
      "metadata": {},
      "source": [
        "**What does the calibration function actually do**: \n",
        "when the system is in the calibration mode, all the curvature arrays will be collated into one large dataset that contains all of them superpositioned such that even if the user isn't completely still (as well as understanding the approximate ranges which are satisfactory such as when deep inhales and exhales take place) a good range of their posture at this stage can be taken.\n",
        "to interpret this, the data after the calibration duration (roughly 30 seconds for actual deployment) is over will form a cluster of what good posture means by seeing - for each index on the spine, since each instance is a discretised array of 250 points - what the typical range of values is and defining an anomaly. I previously used standard deviation and the arithmetic mean but it showed errors when there were greater than 3 sensors (maybe because the shape cannot form a normally distributed shape?) so I was now looking at a one-class support vector machine which will \"understand\" that the current input data is \"good\" and give a value to which new data comes in to determine whether it is \"good\" or \"bad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r5scoXCdFG3C",
      "metadata": {
        "id": "r5scoXCdFG3C"
      },
      "outputs": [],
      "source": [
        "class SpineAnalysis:\n",
        "    def __init__(self, t_values):\n",
        "        self.is_calibrating = True\n",
        "        self.calibration_duration = 30\n",
        "        self.calibration_dataset = []\n",
        "        self.timer = time.time()\n",
        "\n",
        "        self.deviance_indices = [] \n",
        "\n",
        "        self.poor_posture_timer = 5\n",
        "        self.poor_posture_start = None # using time.time() (or more efficient/local clocks for performance reasons)\n",
        "        self.poor_posture_ticker = 0 # it increments if there is an instance of poor posture detect\n",
        "        self.sustained_poor_posture = False\n",
        "\n",
        "        self.cumulative_lengths = t_values\n",
        "        self.segments = None\n",
        "\n",
        "    def dataset_update(self, curvature_instance):\n",
        "        '''\n",
        "        INPUT: curvature_instance\n",
        "        OUTPUT: calibration_dataset\n",
        "        RUNTIME: ['to be called in the main function for duration=calibration-duration']\n",
        "        '''\n",
        "        # exit if this function was mistakenly called\n",
        "        if self.is_calibrating == False:\n",
        "            return \n",
        "\n",
        "        self.calibration_dataset.append(curvature_instance)\n",
        "\n",
        "    def output_calibration_data(self):\n",
        "        '''\n",
        "        INPUT: self.calibration_dataset\n",
        "        OUTPUT: self.calibrated_data\n",
        "        FUNCTION: \n",
        "        '''\n",
        "        calibration_matrix = np.array(self.calibration_dataset)\n",
        "\n",
        "        # for each of the 250 spline positions, compute the IQR bounds \n",
        "        self.calibrated_data = []\n",
        "        for i in range(250):\n",
        "            column = calibration_matrix[:, i]\n",
        "            q1 = np.percentile(column, 25)\n",
        "            q3 = np.percentile(column, 75)\n",
        "            # I commented out these to have basic tests done; complexity comes later.\n",
        "            # iqr = q3 - q1\n",
        "            # a = q1 - (1.5 * iqr)\n",
        "            # b = q3 + (1.5 * iqr) \n",
        "            self.calibrated_data.append((q1, q3))\n",
        "\n",
        "        self.is_calibrating = False\n",
        "\n",
        "    def posture_detector(self, curvature_instance):\n",
        "        '''\n",
        "        INPUT:      curvature_instance\n",
        "        OUTPUT:     if deviation-signal = True; self.poor_posture_ticker += 1,  self.deviance_indices.append(['indices of posture deviances stored in a temporary list structure for each increment step'])\n",
        "        FUNCTION:   Reads current instance of curvature and compares it to the calibration-dataset. If there are any deviances, they are to be taken note of \n",
        "                    if self.poor_posture_ticker >= ['some defined value'] and ['the mean length of the lists in self.deviance_indices is greater than some value (so that noise doesn't cause the whole system to crash)']; reroute this function to a different handling one automatically\n",
        "        '''\n",
        "        curvature_instance = np.array(curvature_instance)\n",
        "        if not self.calibrated_data:\n",
        "            self.output_calibration_data()\n",
        "        \n",
        "        # if there is no current instance of poor posture (i.e no timer) then empty the list for the deviances\n",
        "        if self.poor_posture_ticker == 0: \n",
        "            self.deviance_indices = []\n",
        "\n",
        "        # for each of the 250 spline positions, if the given point is not in the range of the calibrated data it has deviated\n",
        "        local_list = []\n",
        "        for i in range(250):\n",
        "            index = curvature_instance[i]\n",
        "            a = self.calibrated_data[i][0]\n",
        "            b = self.calibrated_data[i][1]\n",
        "            if not (a <= index <= b):\n",
        "                local_list.append(i)\n",
        "        self.deviance_indices.append(np.array(local_list))\n",
        "        \n",
        "        if self.deviance_indices:\n",
        "            self.poor_posture_ticker += 1\n",
        "    \n",
        "        # This should be handled in the main loop, otherwise the unpacking of data would cause crashes:::\n",
        "        # if self.poor_posture_ticker >= 10: # arbitrary value\n",
        "            # self.sustained_posture_deviance()\n",
        "\n",
        "    def sustained_posture_deviance(self, curvature_instance):\n",
        "        '''\n",
        "        INPUT:      curvature_instance, self.deviance_indices\n",
        "        OUTPUT:     signal-to-serial ['e.g. \"HIGH, 4\"']\n",
        "        FUNCTION:   Finds the mean (and weighted temporally) index of where the deviations have been up until the poor_posture_tickers maximum (and ongoing) by checkign through self.deviance_indices. \n",
        "                    I can determine a map of which clusters of areas are deviating and send codes to them. The separation of clusters may be difficult.\n",
        "        '''\n",
        "        # segment the spine with the linear distances to proportionally break down the spine \n",
        "        if self.segments is None:\n",
        "            self.segmentation_algorithm()\n",
        "\n",
        "        # aggregate all the deviated indices from the sliding window into one list\n",
        "        recent_deviations = []\n",
        "        for each_list in self.deviance_indices[-self.poor_posture_timer:]: # this value is dependent on what I have set the max poor_posture_ticker to be, i.e. the poor_posture_timer assuming tick has a time period of a second\n",
        "            recent_deviations.extend(each_list) # rather than append such that it is only one, flattened list (rather than appended subcomponents)\n",
        "\n",
        "        motor_counts = [0] * (len(self.segments) - 1) # one motor per segment (i.e. per IMU)\n",
        " \n",
        "        for indx in recent_deviations:\n",
        "            for seg_i in range(len(self.segments) - 1):\n",
        "                if self.segments[seg_i] <= indx < self.segments[seg_i + 1]:\n",
        "                    motor_counts[seg_i] += 1\n",
        "                    break\n",
        "\n",
        "        # output simple code of [('HIGH'), ('position along spline')]\n",
        "        # NB: there will only be the 'HIGH' setting until further testing\n",
        "\n",
        "        threshold = 5 # arbitrary and only for testing now, this will be made more complex later\n",
        "        commands = []\n",
        "        for motor_id, count in enumerate(motor_counts): # output like (0, 15)\n",
        "            if count > threshold:\n",
        "                commands.append(('HIGH', motor_id)) # the medium and low settings will come after\n",
        "        return commands\n",
        "\n",
        "    def segmentation_algorithm(self):\n",
        "        '''\n",
        "        INPUT:      self.cumulative_distances\n",
        "        OUTPUT:     self.segments\n",
        "        FUNCTION:   Scales the cumulative distances proportionally to the number of created segments in the discretised function (250) and outputs the list of self.segments\n",
        "        '''\n",
        "\n",
        "        self.cumulative_lengths = np.array(self.cumulative_lengths)\n",
        "\n",
        "        # this result outputs a scaled list where 250 is now at the maximum\n",
        "        self.segments = (self.cumulative_lengths / max(self.cumulative_lengths)) * 250\n",
        "\n",
        "    def spatio_temporal_deviance_clustering(self):\n",
        "        '''\n",
        "        This function will have a weighting applied to the deviances in self.deviance_indices that is more responsive and accurate (i.e. more robust to noise)\n",
        "        '''\n",
        "        # cluster (spatially) the deviance_indices\n",
        "\n",
        "        # cluster (temporally) the deviance_indices (in a sliding window of the most recent 5 since these will be continually updated)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CGhkHH6ZFmHv",
      "metadata": {
        "id": "CGhkHH6ZFmHv"
      },
      "source": [
        "### Database Logging\n",
        "Rather than scaffolding with a `.csv` file first, going straight to a database will be just more useful for real data analysis (and storing such large data).\n",
        "\n",
        "Also, pretty complex scripts would be necessary to label the specific times when certain tags are necessary (e.g. \"calibrating\" or \"deviated\") so this is just better practice.\n",
        "\n",
        "Further, looking at how to properly thread this (potentially at a higher frequency) would be more beneficial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tzjYSf_2Flna",
      "metadata": {
        "id": "tzjYSf_2Flna"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "SKibcue9GKGI",
      "metadata": {
        "id": "SKibcue9GKGI"
      },
      "source": [
        "### Plot Setup\n",
        "Quite simple and self-explanatory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pPANt4VpGO1v",
      "metadata": {
        "id": "pPANt4VpGO1v"
      },
      "outputs": [],
      "source": [
        "    fig = plt.figure(figsize=(15,9))\n",
        "    ax = fig.add_subplot(121, projection='3d')\n",
        "    ax2 = fig.add_subplot(122)\n",
        "\n",
        "    # scatter = ax.scatter([], [], [], s=50) # we can scatter later tbh\n",
        "    line, = ax.plot([], [], [])\n",
        "    # scatter_hotspot = ax.scatter([], [], [], color='red', s=50)\n",
        "\n",
        "    curv_line, = ax2.plot([], [])\n",
        "\n",
        "    ax.set_title(\"IMU Positions\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_zlabel(\"Z (m)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YDh2rGpOGBE8",
      "metadata": {
        "id": "YDh2rGpOGBE8"
      },
      "source": [
        "### Animate Function\n",
        "The function that brings together all the helper functions and it written closer to the style of the earlier pseudocode without the initial pitfalls of being completely unable to debug this monolithic block of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j85Yl7iPGnvk",
      "metadata": {
        "id": "j85Yl7iPGnvk"
      },
      "outputs": [],
      "source": [
        "spine_instance = None # the variable that will hold the class \n",
        "last_update_time = time.time() # so that the dt structure in the function doesn't just die\n",
        "\n",
        "def animate(i):\n",
        "    global spine_instance, last_update_time\n",
        "\n",
        "    # dt calculation (that calcs timestep between each call of the function)\n",
        "    current_time = time.time()\n",
        "    dt = current_time - last_update_time\n",
        "    last_update_time = current_time\n",
        "\n",
        "    # check if serial has data\n",
        "    # {INTENTION}: check if serial has data from ALL channels\n",
        "    try:\n",
        "        if not serialInst.in_waiting:\n",
        "            return line, curv_line\n",
        "\n",
        "        line = serialInst.readline().decode('utf-8').strip()\n",
        "        '''\n",
        "        Clean up data such that I can use the IMU class and the helper functions later.\n",
        "        I need to get the data such that it is just direction vector data (and then I can finally just use the 'dt' calculations to properly extract IMU data)\n",
        "        I do not know whether this will cause threading issues (if it does I will remove that functionality an look to understanding threading and toher bttlenecks as I try to code out this function (lord have mercy))\n",
        "        '''\n",
        "        parts = line.split(',')\n",
        "        imu_id = parts[-1]\n",
        "        imu_data = [float(data) for data in parts[:-1]]\n",
        "\n",
        "        '''\n",
        "        I think a better solution would be the storage of data such that the animate function will not run until all the channels (for this specifc timestep) are full (i.e there isn't a continuous (very small, but present) lag in the system).\n",
        "        This would require me rewriting this to account for this lag; what is the complexity of this fix?\n",
        "        '''        \n",
        "        # Here is the categorisation lines which associates the data of each imu to a specific channel that will be read in:\n",
        "        try:\n",
        "            target_imu_index = IMU_ID_LIST.index(str(imu_id)) \n",
        "            imu_deques[target_imu_index].append(imu_data)\n",
        "\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Recieved data from unknown data channel @ ID:{imu_id}\")\n",
        "\n",
        "        # if there is data in all the imu_deques\n",
        "        if all(imu_deques):\n",
        "            # using the data from the imu, get the most specific direction vector positions \n",
        "            filtered_data = []\n",
        "            for i in range(len(imu_deques)):\n",
        "                ___, vector_direction = angle_tilt_filter(imu_deques[i][-1], dt) # (the first output vector will be used for torsion calculations, with the orientation of data changing; for this test, the 'y-direction' is all that is needed)\n",
        "                filtered_data.append(vector_direction)\n",
        "            \n",
        "            # using this, do forward kinematics\n",
        "            position_vectors, t_values = forward_kinematics(filtered_data, linear_distances)\n",
        "\n",
        "            # using this, do cubic spline interpolation\n",
        "            xc, yc, zc, plot_t = cubic_spline_interpolation(position_vectors, t_values)\n",
        "\n",
        "            # using this, do the curvature calcualtion\n",
        "            curvature_instance = curvature_list(plot_t)\n",
        "\n",
        "            # create spine_instance instance if None\n",
        "            if spine_instance is None: \n",
        "                spine_instance = SpineAnalysis(t_values)\n",
        " \n",
        "            # now do calibration \n",
        "            if spine_instance.is_calibrating:\n",
        "                if (time.time() - spine_instance.timer) < spine_instance.calibration_duration:\n",
        "                    spine_instance.dataset_update(curvature_instance)\n",
        "                else:\n",
        "                    spine_instance.output_calibration_data()\n",
        "                    print(\"Calibration Completed\")\n",
        "\n",
        "            # collect the data as usual for the posture detection\n",
        "            spine_instance.posture_detector(curvature_instance)\n",
        "\n",
        "            # now run the conditional if there is a deviation \n",
        "            sustained_threshold = 5  # currently an arbitrary value\n",
        "            if spine_instance.poor_posture_ticker >= sustained_threshold:\n",
        "                commands = spine_instance.sustained_posture_deviance(curvature_instance)\n",
        "                for level, motor_id in commands:\n",
        "                    cmd = f\"{level},{motor_id}\\n\"\n",
        "                    try:\n",
        "                        serialInst.write(cmd.encode('utf-8'))\n",
        "                    except Exception as e:\n",
        "                        print(\"Failed to send command:\", e)\n",
        "                # reset ticker and deviance list\n",
        "                spine_instance.poor_posture_ticker = 0\n",
        "                spine_instance.deviance_indices = []\n",
        "\n",
        "            # 3D plot of interpolated spine\n",
        "            line.set_data(xc(plot_t), yc(plot_t))\n",
        "            line.set_3d_properties(zc(plot_t)) \n",
        "\n",
        "            # graph of the curvature distribution against index (that also dynamically updates)\n",
        "            x = np.arange(len(curvature_instance)) # which should be 250, but just to make sure\n",
        "            y = curvature_instance\n",
        "            curv_line.set_data(x, y)\n",
        "            \n",
        "    except (ValueError, IndexError) as e:\n",
        "        print(f\"Serial line error: {e}\")\n",
        "        return line, curv_line\n",
        "\n",
        "anim = FuncAnimation(fig, animate, cache_frame_data=False, interval=100, blit=False) # blitting only draws the dynamic aspects of the plot\n",
        "# apprently blitting in 3d is less cool so I got rid of it \n",
        "\n",
        "ax.set_box_aspect([1,1,1])\n",
        "ax.set_proj_type('ortho')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8abtHhFuGobe",
      "metadata": {
        "id": "8abtHhFuGobe"
      },
      "source": [
        "### Exceptions & Error Handling\n",
        "This is the error handling for the entire system.\n",
        "\n",
        "Sometimes, for some previous tests, the system freezes and I kind of don't want that to happen so looking at ways of stopping the program without the risk of it fully crashing would be nice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ft4s8DwAIfog",
      "metadata": {
        "id": "Ft4s8DwAIfog"
      },
      "outputs": [],
      "source": [
        "except Exception as e:\n",
        "    exc_type, exc_value, exc_traceback = sys.exc_info()\n",
        "    line_number = exc_traceback.tb_lineno\n",
        "    print(f\"ERROR: {e}, line {line_number}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
