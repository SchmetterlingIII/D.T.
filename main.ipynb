{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SchmetterlingIII/D.T./blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0617d7",
      "metadata": {
        "id": "4a0617d7"
      },
      "source": [
        "This is an improvement from the initial `spline-interp.ipynb` with a focus on a clearer preceding pseudocode as well as code structure, with classes and helper functions being developed first."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps\n",
        "\n",
        "3. calibration phase (extenstion is storing of the data at the same frequency for now in a database)\n",
        "4. the other spineclass functions (deviation handling and all that, adding other ones for prolonged static posture as well)\n",
        "5. animate plottin\n",
        "6. extension (visual cues in plotting, more detail on calibration stats)"
      ],
      "metadata": {
        "id": "yIhyOo_Cg-FA"
      },
      "id": "yIhyOo_Cg-FA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checklist\n",
        "**27/11/25**\n",
        "- write the full spine analysis function (in whatever the simplest form looks like)\n",
        "- get started on the animate function\n",
        "\n",
        "**28/11/25**\n",
        "- finish the animate function and run the whole thing\n",
        "\n",
        "**29/11 -> interview**\n",
        "- debug and *get some useful output from this that can be shown on a graph (like the graph on this paper `file:///C:/Users/25okotir/Downloads/2018_ICCSA_PostureSensei_Preprint.pdf`)\n"
      ],
      "metadata": {
        "id": "-Asgqr8aG8va"
      },
      "id": "-Asgqr8aG8va"
    },
    {
      "cell_type": "markdown",
      "id": "6518cea5",
      "metadata": {
        "id": "6518cea5"
      },
      "source": [
        "# Pseudocode\n",
        "\n",
        "- Read in the data from the serial and unpack it so that it can be interpreted\n",
        "- Clean up this data further such that the accelerometer data is cleaned (`madgwick-filter(accelerometer_data)`) and the output of this are the direction vectors of the tilt. *Further improvements to this function could also input the gyroscope and magnetometer data and have a more comprehensive input--the output will still be the direction vector of the tilt for each IMU so it doesn't change much*.\n",
        "- Interpolate this appropriately (`forward-kinematics` then `cubic-spline-interp` is the current approach)\n",
        "- Curvature analysis class that -- using whatever interpolated functions -- creates a list of the curvatures at each input\n",
        "    - at first, the calibration phase happens where a distribution of the inputted curvatures (wrt their indices and time) are plotted for that duration (i.e. the state `calibration_duration`). This distribution is stored and then checked against for each instance outside of this test phase. I intend to use one-class support vector machine (SVM) but not sure currently. With enough tests (and ML that happens offline) I would like to produce a very inexpensive and accurate method of interpreting the data in the calibration phase but I am not sure currently and need guidance on how to interpret this data (in semi-real time).\n",
        "    - After this, if an inputted curvature (i.e. instance of the digital twin of the user's spine) has deviated beyond a defined boundary (**how should this be defined?**) then the segment of the spine that this data falls within (which has a corresponding haptic motor) will be alerted through the serial and vibrate on the area of deviation. On the updated plot, there will be a red dots along the arclength of deviation for an update.\n",
        "        - (for future proofing, I would also like for if there are high instances of static posture, but this feels like just another function and having the if condition be `if deviated or prolonged-static` where both of those are states within the class)\n",
        "    - Otherwise, there is just a plot of the digital twin on the screen (what other metrics would be cool to have later?)\n",
        "- plot the interpolated spline at a lower frequency than data is being interpreted and stored in database\n",
        "- all of this data needs to be stored in a database for ML later and a clearer interpretation of what is happening at specific timesteps and to isolate errors that can be debugged"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "QDfnx1Jctl7S"
      },
      "id": "QDfnx1Jctl7S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Module Imports"
      ],
      "metadata": {
        "id": "1O7O-U3EuSQy"
      },
      "id": "1O7O-U3EuSQy"
    },
    {
      "cell_type": "code",
      "source": [
        "import serial.tools.list_ports\n",
        "import string\n",
        "import serial\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from  mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "import scipy\n",
        "import sys # specifically for debugging"
      ],
      "metadata": {
        "id": "64AcUw_StsXs"
      },
      "id": "64AcUw_StsXs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serial Reading"
      ],
      "metadata": {
        "id": "9On7yIm_trSN"
      },
      "id": "9On7yIm_trSN"
    },
    {
      "cell_type": "code",
      "source": [
        "BAUDRATE = 115200\n",
        "try:\n",
        "    '''\n",
        "    Basic setup for port communication\n",
        "    '''\n",
        "\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    serialInst = serial.Serial()\n",
        "    portList = [str(i) for i in ports]\n",
        "    print(portList)\n",
        "\n",
        "    com = input(\"Select COM PORT for Arduino: \")\n",
        "\n",
        "    for i in range(len(portList)):\n",
        "        if portList[i].startswith(\"COM\" + str(com)):\n",
        "            SERIAL_PORT = \"COM\" + str(com)\n",
        "            print(SERIAL_PORT)\n",
        "\n",
        "    serialInst.baudrate = BAUDRATE\n",
        "    serialInst.port = SERIAL_PORT\n",
        "    serialInst.open()\n",
        "    print(f\"Connected to {SERIAL_PORT} at {BAUDRATE} baud.\")\n",
        "\n",
        "    '''\n",
        "    Initial data initialisation.\n",
        "    This is a complementary function to the c++ code which says how many sensors are connected and which positions they are in.\n",
        "    '''\n",
        "    while True:\n",
        "        line = serialInst.readline().decode('utf-8') # each line is the decoded form of the serial\n",
        "        if line: # if there is data in the readline i.e if line == True\n",
        "            print(f\"Arduino: {line}\")\n",
        "        if \"Available channels: \" in line:\n",
        "            channels_part = line.split(\":\")[-1].strip() # extract all data after colon\n",
        "            # parse the csv into on stringed list\n",
        "            IMU_ID_LIST = [id.strip() for id in channels_part.split(\",\") if id.strip()]\n",
        "        if \"Number of sensors: \" in line:\n",
        "           ID_NUM = int(line.strip(\":\")[-3]) # the number of read sensors, last instance is \"\\n\" and so index = -3 is the appropriate index\n",
        "           IMU_DEQUES = [deque(maxlen=50) for i in range(ID_NUM)]\n",
        "        if \"Waiting for 'begin program' command\" in line:\n",
        "            break\n",
        "\n",
        "    '''\n",
        "    Input of linear distances for the forward kinematics chain (and subsequent calculations)\n",
        "    '''\n",
        "    print(\"INSTRUCTIONS:\\nInput the linear distances between your sensors in metres.\\nMeasure from lowest to highest.\\nI would recommend using a high resolution ruler to reduce drift.\\n\")\n",
        "    linear_distances = []\n",
        "    for i in range(ID_NUM - 1):\n",
        "        value = float(input(f\"{i + 1}: \"))\n",
        "        linear_distances.append(value)\n",
        "\n",
        "    print(\"Sending 'begin' command to Arduino\")\n",
        "    serialInst.write(b'begin program') # sent in bytes rather than a high level string since it is sent to back to the compiler\n",
        "\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "id": "7LDtVg4GuW3g"
      },
      "id": "7LDtVg4GuW3g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions\n",
        "- data filtering (madgwick filter)\n",
        "- forward kinematics function\n",
        "- cubic spline (outputting discretised function)"
      ],
      "metadata": {
        "id": "TV9aw1p7xnT-"
      },
      "id": "TV9aw1p7xnT-"
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_tilt_filter(IMU_data, dt):\n",
        "    '''\n",
        "    https://www.youtube.com/watch?v=7VW_XVbtu9k\n",
        "    Use the above video to extract the angle between each of the IMUs.\n",
        "\n",
        "    This is less susceptible to gyro tilt over time\n",
        "\n",
        "    Return: normalised matrix containing the vector values of each of the filtered IMUs using this angle extraction method.\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    each data is streamed one at a time.\n",
        "    find the local pitch and yaw\n",
        "    from these angles, get the appropriate direction vector\n",
        "    store into the matrix\n",
        "\n",
        "    return np.array([(), (), (), ..., ()])\n",
        "    '''\n",
        "\n",
        "    accel_angle_x = np.arctan2(ay, az) # about the x-axis\n",
        "    accel_angle_y = np.arctan2(ax, az) # about the y-axis\n",
        "\n",
        "    gyro_x += gyro_x * dt\n",
        "    gyro_y += gyro_y * dt\n",
        "\n",
        "    # rather than a filter yet, I will just have a bias towards angular tilt\n",
        "    fused_angle_x = 0.98 * (gyro_x) + 0.02 * accel_angle_x # roll\n",
        "    fused_angle_y = 0.98 * (gyro_y) + 0.02 * accel_angle_y # pitch\n",
        "\n",
        "def angles_to_direction_vector(roll, pitch):\n",
        "    '''\n",
        "    Calculates normal vector and direction vector in direction of y-axis.\n",
        "\n",
        "    The y-axis direction vector will be used for the forward kinematics; the normal vector will reinforce calculations of curvature (and be the precursor to having a 3D understanding of curvature along the spine).\n",
        "    '''\n",
        "    # normal\n",
        "    normal = np.array([\n",
        "        np.sin(pitch) * np.cos(roll),\n",
        "        -np.sin(roll),\n",
        "        np.cos(roll) * np.cos(pitch)\n",
        "    ])\n",
        "\n",
        "    # y direction\n",
        "    y_direction = np.array([\n",
        "        np.sin(pitch) * np.sin(roll),\n",
        "        np.cos(roll),\n",
        "        np.cos(pitch) * np.sin(roll)\n",
        "    ])\n",
        "\n",
        "    normal = normal / np.linalg.norm(normal)\n",
        "    y_direction = y_direction / np.linalg.norm(y_direction)\n",
        "\n",
        "    return normal, y_direction\n",
        "\n",
        "def kalman_filter(angle_filtered_data):\n",
        "    '''\n",
        "    https://www.youtube.com/watch?v=5HuN9iL-zxU&list=PLeuMA6tJBPKsAfRfFuGrEljpBow5hPVD4&index=18\n",
        "    Another tutorial that will help me actually have an accurate input of the data, without resorting to l'IA or learning the maths behind this.\n",
        "\n",
        "    I will look into how Kalman filters work from a high level but if there is a python module for it then I will be happy to just copy it.\n",
        "    '''\n",
        "    return filtered_data\n",
        "\n",
        "def forward_kinematics(filtered_data, linear_distances):\n",
        "    '''\n",
        "    Computes positions using the IMU data and distances, assuming that the base IMU is at the origin.\n",
        "    Returns: list of 3D positions where the IMUs are in an arbitrary & scaled 3D space\n",
        "\n",
        "    For later improvements, I will use quaternions to handle the tilt as done in the CHARM Lab device.\n",
        "    '''\n",
        "\n",
        "    # if no data, return nothing important (in the same format which can be unpacked but not causing a crash)\n",
        "    if not filtered_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    origin = np.array([0,0,0])\n",
        "    p_n = [origin]\n",
        "    cumulative_distance = 0\n",
        "    t_values = [0]\n",
        "\n",
        "    for i in range(len(filtered_data)):\n",
        "        v_n = filtered_data[i] # the direction vector at this point\n",
        "        l_n = linear_distances[i] if i != (len(filtered_data) - 1) else 0.1 # the scalar distance between the upcoming sensor and the current\n",
        "        # I have added the 0.1 since the final IMU will not have a subsequent sensor to work towards so this tilt will approximate what's happening up to the neck area\n",
        "\n",
        "        p_n_plus_1 = p_n[-1] + (v_n * l_n) # the next position vector along the chain\n",
        "        p_n.append(p_n_plus_1)\n",
        "\n",
        "        cumulative_distance += l_n\n",
        "        t_values.append(cumulative_distance)\n",
        "\n",
        "    return p_n, t_values # returns vector position & t_values for interpolation\n",
        "\n",
        "def cubic_spline_interpolation(IMU_positions, t_values):\n",
        "    '''\n",
        "    Interpolates the function using the formed kinematic chain in a parametrised format.\n",
        "\n",
        "    Returns the plotting values\n",
        "    '''\n",
        "    x = IMU_positions[:, 0]\n",
        "    y = IMU_positions[:, 1]\n",
        "    z = IMU_positions[:, 2]\n",
        "\n",
        "    xc = CubicSpline(t_values, x)\n",
        "    yc = CubicSpline(t_values, y)\n",
        "    zc = CubicSpline(t_values, z)\n",
        "\n",
        "    # this variable stores the t_values that are along this interpolated spline in a discrete package i.e. \"plotting_t_values\"\n",
        "    discrete_points = 250\n",
        "    plot_t = np.linspace(min(t_values), max(t_values), discrete points)\n",
        "\n",
        "    return xc, yc, zc, plot_t\n",
        "\n",
        "def curvature_list(plot_t):\n",
        "    '''\n",
        "    This function returns an array of scalar curvatures for each point on the interpolated spline function.\n",
        "\n",
        "    The issue with this (for future reference) is that these points only show a scalar and so improvements of this could be to interpolate the normal values of the vectors along the function to have a better understanding of curvature in 3D space.\n",
        "    '''\n",
        "    r = (xc(plot_t, 0), yc(plot_t, 0), zc(plot_t, 0))\n",
        "    r_prime = (xc(plot_t, 1), yc(plot_t, 1), zc(plot_t, 1))\n",
        "    r_double_prime = (xc(plot_t, 2), yc(plot_t, 2), zc(plot_t, 2))\n",
        "\n",
        "    kappa = (np.linalg.norm(np.cross(r_prime, r_double_prime)))/(np.linalg.norm(r_prime)**3)\n",
        "    return kappa # an array of scalar values for the curvature along this interpolated spline\n"
      ],
      "metadata": {
        "id": "TWzkjXb0yn4S"
      },
      "id": "TWzkjXb0yn4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMU Class\n",
        "This just holds the state for each of the IMUs (their direction vectors) and the `dt` for each of it. Further, it will hold how filtered the data is as a quality."
      ],
      "metadata": {
        "id": "sRlJb16lQGth"
      },
      "id": "sRlJb16lQGth"
    },
    {
      "cell_type": "code",
      "source": [
        "class IMU_data:\n",
        "    def __init__(self):\n",
        "        self.direction_vector = None\n",
        "        self.time = time.time() # used for calculating the `dt` of the sensors"
      ],
      "metadata": {
        "id": "r9i6WIeBQ5Jr"
      },
      "id": "r9i6WIeBQ5Jr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spine Analysis Class\n",
        "This is the class that effectively analyses the instance of the curvature and, by comparing this instance with the distribution of curvatures stored during the calibration mode, outputs whether there is (a) a deviation from \"good\" posture* or (b) prolonged static posture.\n",
        "\n",
        "*The feeback mechanism of this is inherently flawed given there shows diminishing links to this effect. However, working towards the distribution is still a good reason to learn ML (and with enough data, this awareness and deviation from \"current posture\" will help to inform more complex decisions of when alerts should go off)."
      ],
      "metadata": {
        "id": "stFde0UOEZ1q"
      },
      "id": "stFde0UOEZ1q"
    },
    {
      "cell_type": "code",
      "source": [
        "class SpineAnalysis:\n",
        "    def __init__(self):\n",
        "        self.is_calibrating = True\n",
        "        self.baseline_curvature = None\n",
        "        self.calibration_duration = 30\n",
        "        self.calibration_dataset = None\n",
        "\n",
        "\n",
        "        self.poor_posture_timer = 5\n",
        "        self.poor_posture_start = None # using time.time() (or more efficient/local clocks for performance reasons)\n",
        "\n",
        "    def calibration_phase(self, curvature_instance):\n",
        "        '''\n",
        "        This calibrates, using statistical distributions, what the user's baseline posture is in a semi-static way.\n",
        "\n",
        "        Result: storing values to know what a good posture looks like (learning one-class SVM is not worth it currently but good to consider for later)\n",
        "        '''\n",
        "        # exit if this function was mistakenly called\n",
        "        if self.is_calibrating = False:\n",
        "            # exit this function\n",
        "\n",
        "        # initially the data is being collected so this should be stored in the calibration-dataset\n",
        "        self.calibration_dataset.append(curvature_instance)\n",
        "\n",
        "        elapsed_time = time.time() - self.calibration_duration\n",
        "        if elapsed_time > self.calibration_duration:\n",
        "            # now there will be attempts at understanding how this data is distributed and what a \"deviation\" looks like\n",
        "\n",
        "        self.is_calibrating = False\n",
        "        print(\"\\nNOW EXITING CALIBRATION PHASE\\n\\n\")\n",
        "\n",
        "    def posture_deviance(self, curvature_instance):\n",
        "        '''\n",
        "        Records any instance of posture deviation anywhere. If it goes on for a time greater than the threshold then another function will be called to handle this.\n",
        "        '''\n",
        "\n",
        "    def sustained_posture_deviance(self, curvature_instance):\n",
        "        '''\n",
        "        1. Find where along the spline this has occurred\n",
        "        2. Map this with the segments from the interpolation and output that\n",
        "        '''\n"
      ],
      "metadata": {
        "id": "r5scoXCdFG3C"
      },
      "id": "r5scoXCdFG3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Database Logging\n",
        "Rather than scaffolding with a `.csv` file first, going straight to a database will be just more useful for real data analysis (and storing such large data).\n",
        "\n",
        "Also, pretty complex scripts would be necessary to label the specific times when certain tags are necessary (e.g. \"calibrating\" or \"deviated\") so this is just better practice.\n",
        "\n",
        "Further, looking at how to properly thread this (potentially at a higher frequency) would be more beneficial."
      ],
      "metadata": {
        "id": "CGhkHH6ZFmHv"
      },
      "id": "CGhkHH6ZFmHv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tzjYSf_2Flna"
      },
      "id": "tzjYSf_2Flna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Setup\n",
        "Quite simple and self-explanatory."
      ],
      "metadata": {
        "id": "SKibcue9GKGI"
      },
      "id": "SKibcue9GKGI"
    },
    {
      "cell_type": "code",
      "source": [
        "    fig = plt.figure(figsize=(15,9))\n",
        "    ax = fig.add_subplot(121, projection='3d')\n",
        "    ax2 = fig.add_subplot(122)\n",
        "\n",
        "    ## set the points for the animate(i) function\n",
        "    ## these variables are what are updated (and saves clearing the plot each time)\n",
        "    scatter = ax.scatter([], [], [], s=50)\n",
        "    line, = ax.plot([], [], [])\n",
        "    scatter_hotspot = ax.scatter([], [], [], color='red', s=50)\n",
        "\n",
        "    ax.set_title(\"IMU Positions\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_zlabel(\"Z (m)\")"
      ],
      "metadata": {
        "id": "pPANt4VpGO1v"
      },
      "id": "pPANt4VpGO1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Animate Function\n",
        "The function that brings together all the helper functions and it written closer to the style of the earlier pseudocode without the initial pitfalls of being completely unable to debug this monolithic block of code."
      ],
      "metadata": {
        "id": "YDh2rGpOGBE8"
      },
      "id": "YDh2rGpOGBE8"
    },
    {
      "cell_type": "code",
      "source": [
        "def animate(i):\n",
        "    return scatter, line, scatter_hotspot\n",
        "\n",
        "anim = FuncAnimation(fig, animate, cache_frame_data=False, interval=100, blit=True) # blitting only draws the dynamic aspects of the plot\n",
        "\n",
        "ax.set_box_aspect([1,1,1])\n",
        "ax.set_proj_type('ortho')\n",
        "plt.tight_layout()\n",
        "plt.show() # is plt.show() the most efficient?"
      ],
      "metadata": {
        "id": "j85Yl7iPGnvk"
      },
      "id": "j85Yl7iPGnvk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exceptions & Error Handling\n",
        "This is the error handling for the entire system.\n",
        "\n",
        "Sometimes, for some previous tests, the system freezes and I kind of don't want that to happen so looking at ways of stopping the program without the risk of it fully crashing would be nice."
      ],
      "metadata": {
        "id": "8abtHhFuGobe"
      },
      "id": "8abtHhFuGobe"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft4s8DwAIfog"
      },
      "id": "Ft4s8DwAIfog",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}