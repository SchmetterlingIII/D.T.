{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SchmetterlingIII/D.T./blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0617d7",
      "metadata": {
        "id": "4a0617d7"
      },
      "source": [
        "This is an improvement from the initial `spline-interp.ipynb` with a focus on a clearer preceding pseudocode as well as code structure, with classes and helper functions being developed first."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yIhyOo_Cg-FA",
      "metadata": {
        "id": "yIhyOo_Cg-FA"
      },
      "source": [
        "### Next Steps\n",
        "\n",
        "3. calibration phase (extenstion is storing of the data at the same frequency for now in a database)\n",
        "4. the other spineclass functions (deviation handling and all that, adding other ones for prolonged static posture as well)\n",
        "5. animate plottin\n",
        "6. extension (visual cues in plotting, more detail on calibration stats)\n",
        "\n",
        "**Extensions: very good additions that can focus on UI/UX**\n",
        "- export calibration report (which is the best idea currently) which exports two files:\n",
        "    - `.png` of the matplotlib render of the aggregated data points of the spine with a region that shows what a deviation would look like\n",
        "    - `.txt` that -- given a template that I will write -- exports what the data that you see means so that the user can have it\n",
        "    - future proofing would make this into a more cohesive `.pdf` or cleaner user interface but this is good enough\n",
        "- a subplot showing frame rate and latency (using `perf.counter`) to later be able to calculate the battery usage if integrated with other software or being worn remotely\n",
        "- being able to run this in real time during the interview (with the interface and sharing my screen)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6518cea5",
      "metadata": {
        "id": "6518cea5"
      },
      "source": [
        "# Pseudocode\n",
        "\n",
        "- Read in the data from the serial and unpack it so that it can be interpreted\n",
        "- Clean up this data further such that the accelerometer data is cleaned (`madgwick-filter(accelerometer_data)`) and the output of this are the direction vectors of the tilt. *Further improvements to this function could also input the gyroscope and magnetometer data and have a more comprehensive input--the output will still be the direction vector of the tilt for each IMU so it doesn't change much*.\n",
        "- Interpolate this appropriately (`forward-kinematics` then `cubic-spline-interp` is the current approach)\n",
        "- Curvature analysis class that -- using whatever interpolated functions -- creates a list of the curvatures at each input\n",
        "    - at first, the calibration phase happens where a distribution of the inputted curvatures (wrt their indices and time) are plotted for that duration (i.e. the state `calibration_duration`). This distribution is stored and then checked against for each instance outside of this test phase. I intend to use one-class support vector machine (SVM) but not sure currently. With enough tests (and ML that happens offline) I would like to produce a very inexpensive and accurate method of interpreting the data in the calibration phase but I am not sure currently and need guidance on how to interpret this data (in semi-real time).\n",
        "    - After this, if an inputted curvature (i.e. instance of the digital twin of the user's spine) has deviated beyond a defined boundary (**how should this be defined?**) then the segment of the spine that this data falls within (which has a corresponding haptic motor) will be alerted through the serial and vibrate on the area of deviation. On the updated plot, there will be a red dots along the arclength of deviation for an update.\n",
        "        - (for future proofing, I would also like for if there are high instances of static posture, but this feels like just another function and having the if condition be `if deviated or prolonged-static` where both of those are states within the class)\n",
        "    - Otherwise, there is just a plot of the digital twin on the screen (what other metrics would be cool to have later?)\n",
        "- plot the interpolated spline at a lower frequency than data is being interpreted and stored in database\n",
        "- all of this data needs to be stored in a database for ML later and a clearer interpretation of what is happening at specific timesteps and to isolate errors that can be debugged"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QDfnx1Jctl7S",
      "metadata": {
        "id": "QDfnx1Jctl7S"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1O7O-U3EuSQy",
      "metadata": {
        "id": "1O7O-U3EuSQy"
      },
      "source": [
        "### Module Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64AcUw_StsXs",
      "metadata": {
        "id": "64AcUw_StsXs"
      },
      "outputs": [],
      "source": [
        "import serial.tools.list_ports\n",
        "import string\n",
        "import serial\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from  mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "import scipy\n",
        "import sys # specifically for debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9On7yIm_trSN",
      "metadata": {
        "id": "9On7yIm_trSN"
      },
      "source": [
        "### Serial Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7LDtVg4GuW3g",
      "metadata": {
        "id": "7LDtVg4GuW3g"
      },
      "outputs": [],
      "source": [
        "BAUDRATE = 115200\n",
        "try:\n",
        "    '''\n",
        "    Basic setup for port communication\n",
        "    '''\n",
        "\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    serialInst = serial.Serial()\n",
        "    portList = [str(i) for i in ports]\n",
        "    print(portList)\n",
        "\n",
        "    com = input(\"Select COM PORT for Arduino: \")\n",
        "\n",
        "    for i in range(len(portList)):\n",
        "        if portList[i].startswith(\"COM\" + str(com)):\n",
        "            SERIAL_PORT = \"COM\" + str(com)\n",
        "            print(SERIAL_PORT)\n",
        "\n",
        "    serialInst.baudrate = BAUDRATE\n",
        "    serialInst.port = SERIAL_PORT\n",
        "    serialInst.open()\n",
        "    print(f\"Connected to {SERIAL_PORT} at {BAUDRATE} baud.\")\n",
        "\n",
        "    '''\n",
        "    Initial data initialisation.\n",
        "    This is a complementary function to the c++ code which says how many sensors are connected and which positions they are in.\n",
        "    '''\n",
        "    while True:\n",
        "        line = serialInst.readline().decode('utf-8') # each line is the decoded form of the serial\n",
        "        if line: # if there is data in the readline i.e if line == True\n",
        "            print(f\"Arduino: {line}\")\n",
        "        if \"Available channels: \" in line:\n",
        "            channels_part = line.split(\":\")[-1].strip() # extract all data after colon\n",
        "            # parse the csv into on stringed list\n",
        "            IMU_ID_LIST = [id.strip() for id in channels_part.split(\",\") if id.strip()]\n",
        "        if \"Number of sensors: \" in line:\n",
        "           ID_NUM = int(line.strip(\":\")[-3]) # the number of read sensors, last instance is \"\\n\" and so index = -3 is the appropriate index\n",
        "           IMU_DEQUES = [deque(maxlen=50) for i in range(ID_NUM)]\n",
        "        if \"Waiting for 'begin program' command\" in line:\n",
        "            break\n",
        "\n",
        "    '''\n",
        "    Input of linear distances for the forward kinematics chain (and subsequent calculations)\n",
        "    '''\n",
        "    print(\"INSTRUCTIONS:\\nInput the linear distances between your sensors in metres.\\nMeasure from lowest to highest.\\nI would recommend using a high resolution ruler to reduce drift.\\n\")\n",
        "    linear_distances = []\n",
        "    for i in range(ID_NUM - 1):\n",
        "        value = float(input(f\"{i + 1}: \"))\n",
        "        linear_distances.append(value)\n",
        "\n",
        "    print(\"Sending 'begin' command to Arduino\")\n",
        "    serialInst.write(b'begin program') # sent in bytes rather than a high level string since it is sent to back to the compiler\n",
        "\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TV9aw1p7xnT-",
      "metadata": {
        "id": "TV9aw1p7xnT-"
      },
      "source": [
        "### Helper Functions\n",
        "- data filtering (madgwick filter)\n",
        "- forward kinematics function\n",
        "- cubic spline (outputting discretised function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TWzkjXb0yn4S",
      "metadata": {
        "id": "TWzkjXb0yn4S"
      },
      "outputs": [],
      "source": [
        "def angle_tilt_filter(IMU_data, dt):\n",
        "    '''\n",
        "    https://www.youtube.com/watch?v=7VW_XVbtu9k\n",
        "    Use the above video to extract the angle between each of the IMUs.\n",
        "\n",
        "    This is less susceptible to gyro tilt over time\n",
        "\n",
        "    Return: normalised matrix containing the vector values of each of the filtered IMUs using this angle extraction method.\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    each data is streamed one at a time.\n",
        "    find the local pitch and yaw\n",
        "    from these angles, get the appropriate direction vector\n",
        "    store into the matrix\n",
        "\n",
        "    return np.array([(), (), (), ..., ()])\n",
        "    '''\n",
        "\n",
        "    accel_angle_x = np.arctan2(ay, az) # about the x-axis\n",
        "    accel_angle_y = np.arctan2(ax, az) # about the y-axis\n",
        "\n",
        "    gyro_x += gyro_x * dt\n",
        "    gyro_y += gyro_y * dt\n",
        "\n",
        "    # rather than a filter yet, I will just have a bias towards angular tilt\n",
        "    # these numbers are arbitrary (copied from the video) but I will move onto Kalman filtering later\n",
        "    fused_angle_x = 0.98 * (gyro_x) + 0.02 * accel_angle_x # roll\n",
        "    fused_angle_y = 0.98 * (gyro_y) + 0.02 * accel_angle_y # pitch\n",
        "\n",
        "def angles_to_direction_vector(roll, pitch):\n",
        "    '''\n",
        "    Calculates normal vector and direction vector in direction of y-axis.\n",
        "\n",
        "    The y-axis direction vector will be used for the forward kinematics; the normal vector will reinforce calculations of curvature (and be the precursor to having a 3D understanding of curvature along the spine).\n",
        "    '''\n",
        "    # normal\n",
        "    normal = np.array([\n",
        "        np.sin(pitch) * np.cos(roll),\n",
        "        -np.sin(roll),\n",
        "        np.cos(roll) * np.cos(pitch)\n",
        "    ])\n",
        "\n",
        "    # y direction\n",
        "    y_direction = np.array([\n",
        "        np.sin(pitch) * np.sin(roll),\n",
        "        np.cos(roll),\n",
        "        np.cos(pitch) * np.sin(roll)\n",
        "    ])\n",
        "\n",
        "    normal = normal / np.linalg.norm(normal)\n",
        "    y_direction = y_direction / np.linalg.norm(y_direction)\n",
        "\n",
        "    return normal, y_direction\n",
        "\n",
        "def kalman_filter(angle_filtered_data):\n",
        "    '''\n",
        "    https://www.youtube.com/watch?v=5HuN9iL-zxU&list=PLeuMA6tJBPKsAfRfFuGrEljpBow5hPVD4&index=18\n",
        "    Another tutorial that will help me actually have an accurate input of the data, without resorting to l'IA or learning the maths behind this.\n",
        "\n",
        "    I will look into how Kalman filters work from a high level but if there is a python module for it then I will be happy to just copy it.\n",
        "    '''\n",
        "    return filtered_data\n",
        "\n",
        "def forward_kinematics(filtered_data, linear_distances):\n",
        "    '''\n",
        "    Computes positions using the IMU data and distances, assuming that the base IMU is at the origin.\n",
        "    Returns: list of 3D positions where the IMUs are in an arbitrary & scaled 3D space\n",
        "\n",
        "    For later improvements, I will use quaternions to handle the tilt as done in the CHARM Lab device.\n",
        "    '''\n",
        "\n",
        "    # if no data, return nothing important (in the same format which can be unpacked but not causing a crash)\n",
        "    if not filtered_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    origin = np.array([0,0,0])\n",
        "    p_n = [origin]\n",
        "    cumulative_distance = 0\n",
        "    t_values = [0]\n",
        "\n",
        "    for i in range(len(filtered_data)):\n",
        "        v_n = filtered_data[i] # the direction vector at this point\n",
        "        l_n = linear_distances[i] if i != (len(filtered_data) - 1) else 0.1 # the scalar distance between the upcoming sensor and the current\n",
        "        # I have added the 0.1 since the final IMU will not have a subsequent sensor to work towards so this tilt will approximate what's happening up to the neck area\n",
        "\n",
        "        p_n_plus_1 = p_n[-1] + (v_n * l_n) # the next position vector along the chain\n",
        "        p_n.append(p_n_plus_1)\n",
        "\n",
        "        cumulative_distance += l_n\n",
        "        t_values.append(cumulative_distance)\n",
        "\n",
        "    return p_n, t_values # returns vector position & t_values for interpolation\n",
        "\n",
        "def cubic_spline_interpolation(IMU_positions, t_values):\n",
        "    '''\n",
        "    Interpolates the function using the formed kinematic chain in a parametrised format.\n",
        "\n",
        "    Returns the plotting values\n",
        "    '''\n",
        "    x = IMU_positions[:, 0]\n",
        "    y = IMU_positions[:, 1]\n",
        "    z = IMU_positions[:, 2]\n",
        "\n",
        "    xc = CubicSpline(t_values, x)\n",
        "    yc = CubicSpline(t_values, y)\n",
        "    zc = CubicSpline(t_values, z)\n",
        "\n",
        "    # this variable stores the t_values that are along this interpolated spline in a discrete package i.e. \"plotting_t_values\"\n",
        "    discrete_points = 250\n",
        "    plot_t = np.linspace(min(t_values), max(t_values), discrete points)\n",
        "\n",
        "    return xc, yc, zc, plot_t\n",
        "\n",
        "def curvature_list(plot_t):\n",
        "    '''\n",
        "    This function returns an array of scalar curvatures for each point on the interpolated spline function.\n",
        "\n",
        "    The issue with this (for future reference) is that these points only show a scalar and so improvements of this could be to interpolate the normal values of the vectors along the function to have a better understanding of curvature in 3D space.\n",
        "    '''\n",
        "    r = (xc(plot_t, 0), yc(plot_t, 0), zc(plot_t, 0))\n",
        "    r_prime = (xc(plot_t, 1), yc(plot_t, 1), zc(plot_t, 1))\n",
        "    r_double_prime = (xc(plot_t, 2), yc(plot_t, 2), zc(plot_t, 2))\n",
        "\n",
        "    kappa = (np.linalg.norm(np.cross(r_prime, r_double_prime)))/(np.linalg.norm(r_prime)**3)\n",
        "    return kappa # an array of scalar values for the curvature along this interpolated spline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sRlJb16lQGth",
      "metadata": {
        "id": "sRlJb16lQGth"
      },
      "source": [
        "### IMU Class\n",
        "This just holds the state for each of the IMUs (their direction vectors) and the `dt` for each of it. Further, it will hold how filtered the data is as a quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r9i6WIeBQ5Jr",
      "metadata": {
        "id": "r9i6WIeBQ5Jr"
      },
      "outputs": [],
      "source": [
        "class IMU_data:\n",
        "    def __init__(self):\n",
        "        self.direction_vector = None\n",
        "        self.time = time.time() # used for calculating the `dt` of the sensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stFde0UOEZ1q",
      "metadata": {
        "id": "stFde0UOEZ1q"
      },
      "source": [
        "### Spine Analysis Class\n",
        "This is the class that effectively analyses the instance of the curvature and, by comparing this instance with the distribution of curvatures stored during the calibration mode, outputs whether there is (a) a deviation from \"good\" posture* or (b) prolonged static posture.\n",
        "\n",
        "*The feeback mechanism of this is inherently flawed given there shows diminishing links to this effect. However, working towards the distribution is still a good reason to learn ML (and with enough data, this awareness and deviation from \"current posture\" will help to inform more complex decisions of when alerts should go off)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828c06f4",
      "metadata": {},
      "source": [
        "**What does the calibration function actually do**: \n",
        "when the system is in the calibration mode, all the curvature arrays will be collated into one large dataset that contains all of them superpositioned such that even if the user isn't completely still (as well as understanding the approximate ranges which are satisfactory such as when deep inhales and exhales take place) a good range of their posture at this stage can be taken.\n",
        "to interpret this, the data after the calibration duration (roughly 30 seconds for actual deployment) is over will form a cluster of what good posture means by seeing - for each index on the spine, since each instance is a discretised array of 250 points - what the typical range of values is and defining an anomaly. I previously used standard deviation and the arithmetic mean but it showed errors when there were greater than 3 sensors (maybe because the shape cannot form a normally distributed shape?) so I was now looking at a one-class support vector machine which will \"understand\" that the current input data is \"good\" and give a value to which new data comes in to determine whether it is \"good\" or \"bad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r5scoXCdFG3C",
      "metadata": {
        "id": "r5scoXCdFG3C"
      },
      "outputs": [],
      "source": [
        "class SpineAnalysis:\n",
        "    def __init__(self):\n",
        "        self.is_calibrating = True\n",
        "        self.baseline_curvature = None\n",
        "        self.calibration_duration = 30\n",
        "        self.calibration_dataset = None\n",
        "        self.calibrated_data = None\n",
        "        self.timer = time.time()\n",
        "\n",
        "        self.poor_posture_timer = 5\n",
        "        self.poor_posture_start = None # using time.time() (or more efficient/local clocks for performance reasons)\n",
        "        self.poor_posture_ticker = 0 # it increments if there is an instance of poor posture detect\n",
        "        self.sustained_poor_posture = False\n",
        "        self.deviance_indices = None\n",
        "\n",
        "    def calibration_dataset(self, curvature_instance):\n",
        "        '''\n",
        "        INPUT: curvature_instance\n",
        "        OUTPUT: calibration_dataset\n",
        "        RUNTIME: ['to be called in the main function for duration=calibration-duration']\n",
        "        '''\n",
        "        # exit if this function was mistakenly called\n",
        "        if self.is_calibrating == False:\n",
        "            break \n",
        "\n",
        "        self.calibration_dataset.append(curvature_instance)\n",
        "\n",
        "    def calibration_data(self):\n",
        "        '''\n",
        "        INPUT: self.calibration_dataset\n",
        "        OUTPUT: self.calibrated_data\n",
        "        FUNCTION: \n",
        "        '''\n",
        "\n",
        "    def posture_detector(self, curvature_instance):\n",
        "        '''\n",
        "        INPUT:      curvature_instance\n",
        "        OUTPUT:     if deviation-signal = True; self.poor_posture_ticker += 1,  self.deviance_indices.append(['indices of posture deviances stored in a temporary list structure for each increment step'])\n",
        "        FUNCTION:   Reads current instance of curvature and compares it to the calibration-dataset. If there are any deviances, they are to be taken note of \n",
        "                    if self.poor_posture_ticker >= ['some defined value'] and ['the mean length of the lists in self.deviance_indices is greater than some value (so that noise doesn't cause the whole system to crash)']; reroute this function to a different handling one automatically\n",
        "        '''\n",
        "\n",
        "    def sustained_posture_deviance(self, curvature_instance):\n",
        "        '''\n",
        "        INPUT:      curvature_instance\n",
        "        OUTPUT:     signal-to-serial ['e.g. \"HIGH, 4\"']\n",
        "        FUNCTION:   Finds the mean (and weighted temporally) index of where the deviations have been up until the poor_posture_tickers maximum (and ongoing) by checkign through self.deviance_indices. \n",
        "                    I can determine a map of which clusters of areas are deviating and send codes to them. The separation of clusters may be difficult.\n",
        "        '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c026c12",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "        elapsed_time = time.time() - self.timer # using some fixed value outside of the function to decrement the time is a better process\n",
        "        if elapsed_time > self.calibration_duration:\n",
        "            \"\"\"\n",
        "            The curvature deviances will be stored in a list.\n",
        "            All of these discrete spine instances should be clustered together and stored in a .csv file so that I can actually see this. \n",
        "            But if it is like my assumption then each index roughly has a region that it can fit within and these clusters form the distribution of this\n",
        "\n",
        "            I am thinking, simply, to forget about and to find the IQR for each of the indices of the spine and that is now my range. \n",
        "            The algorithm for detection will be that if there is a cluster of deviated points outside of that range for a period of time, then the alert will be sounded.\n",
        "            To work on this I need to define what cluster (i.e. the cluster of indices, is it two points next to each other, 15? what if some points made it discontinuous (like 2 then fine then 4 then fine continued?))\n",
        "            How to handle the inherent noise from this process?\n",
        "            \"\"\"\n",
        "\n",
        "            # what is the output of this function? \n",
        "            # something to do with self.calibrated_data; how should the data even be stored such that it can be read? \n",
        "            # potentially superimposing the current discretised spine onto the IQR numpy array and seeing for how many indices\n",
        "            # -- and how far away ---\n",
        "            # does the discretised spine deviate from the calibrated one (and to what extent later)\n",
        "\n",
        "            '''\n",
        "            The main issue I have with this thought process is that it might be pretty expensive checking each index for each time this is called -- wouldn't this slow things down. \n",
        "            I am not sure how to consider this properly but it can be saved for debugging time. \n",
        "            '''\n",
        "        self.is_calibrating = False\n",
        "        print(\"\\nNOW EXITING CALIBRATION PHASE\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CGhkHH6ZFmHv",
      "metadata": {
        "id": "CGhkHH6ZFmHv"
      },
      "source": [
        "### Database Logging\n",
        "Rather than scaffolding with a `.csv` file first, going straight to a database will be just more useful for real data analysis (and storing such large data).\n",
        "\n",
        "Also, pretty complex scripts would be necessary to label the specific times when certain tags are necessary (e.g. \"calibrating\" or \"deviated\") so this is just better practice.\n",
        "\n",
        "Further, looking at how to properly thread this (potentially at a higher frequency) would be more beneficial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tzjYSf_2Flna",
      "metadata": {
        "id": "tzjYSf_2Flna"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "SKibcue9GKGI",
      "metadata": {
        "id": "SKibcue9GKGI"
      },
      "source": [
        "### Plot Setup\n",
        "Quite simple and self-explanatory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pPANt4VpGO1v",
      "metadata": {
        "id": "pPANt4VpGO1v"
      },
      "outputs": [],
      "source": [
        "    fig = plt.figure(figsize=(15,9))\n",
        "    ax = fig.add_subplot(121, projection='3d')\n",
        "    ax2 = fig.add_subplot(122)\n",
        "\n",
        "    ## set the points for the animate(i) function\n",
        "    ## these variables are what are updated (and saves clearing the plot each time)\n",
        "    scatter = ax.scatter([], [], [], s=50)\n",
        "    line, = ax.plot([], [], [])\n",
        "    scatter_hotspot = ax.scatter([], [], [], color='red', s=50)\n",
        "\n",
        "    ax.set_title(\"IMU Positions\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_zlabel(\"Z (m)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YDh2rGpOGBE8",
      "metadata": {
        "id": "YDh2rGpOGBE8"
      },
      "source": [
        "### Animate Function\n",
        "The function that brings together all the helper functions and it written closer to the style of the earlier pseudocode without the initial pitfalls of being completely unable to debug this monolithic block of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j85Yl7iPGnvk",
      "metadata": {
        "id": "j85Yl7iPGnvk"
      },
      "outputs": [],
      "source": [
        "def animate(i):\n",
        "    return scatter, line, scatter_hotspot\n",
        "\n",
        "anim = FuncAnimation(fig, animate, cache_frame_data=False, interval=100, blit=True) # blitting only draws the dynamic aspects of the plot\n",
        "\n",
        "ax.set_box_aspect([1,1,1])\n",
        "ax.set_proj_type('ortho')\n",
        "plt.tight_layout()\n",
        "plt.show() # is plt.show() the most efficient?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8abtHhFuGobe",
      "metadata": {
        "id": "8abtHhFuGobe"
      },
      "source": [
        "### Exceptions & Error Handling\n",
        "This is the error handling for the entire system.\n",
        "\n",
        "Sometimes, for some previous tests, the system freezes and I kind of don't want that to happen so looking at ways of stopping the program without the risk of it fully crashing would be nice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ft4s8DwAIfog",
      "metadata": {
        "id": "Ft4s8DwAIfog"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
