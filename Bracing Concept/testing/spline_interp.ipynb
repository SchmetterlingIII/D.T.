{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "04be8da2",
      "metadata": {
        "id": "04be8da2"
      },
      "source": [
        "# Summary of Code\n",
        "Converting IMU data (gyroscope and accelerometer data), I am trying to make a simple digital twin of the spine which can be used as a posture correction device.\n",
        "\n",
        "# Next Steps\n",
        "- quaternions (needs to be done soon). Need to understand the theory and try to properly integrate this. However, for the code I will be using `scipy.spatial.transform.Rotation`rather than writing it all out myself for the sake of efficiency.\n",
        "\n",
        "Here are some videos for this:\n",
        "- **https://www.youtube.com/watch?v=hZrBGiWkUyk&t=504s**: *this actually shows a python integration, but quite lax on the theory behind it all*\n",
        "- https://youtu.be/bKd2lPjl92c?si=yyqcKvoMNcVktlbg\n",
        "- https://youtu.be/zjMuIxRvygQ?si=b8NkCf_LGxgAJK3Y\n",
        "\n",
        "---------------\n",
        "\n",
        "- basic export of data (.csv) and a simple way of scaling (it could be incorporated into a function and then be transferred into an sqlite database)\n",
        "    - This will later be used as the basis for ML training data\n",
        "\n",
        "--------------\n",
        "\n",
        "- improved interpretation of curvature and deviations using clustering ML techniques to help with this project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bFcWEWDdPPR2",
      "metadata": {
        "id": "bFcWEWDdPPR2"
      },
      "source": [
        "## Spline Interpolation\n",
        "*A pretty big note for this is that the constant of 250 (being how many indices are in the list, which can change to make the reading of results more accurate)*\n",
        "\n",
        "\n",
        "- Get the hospot points plotting\n",
        "- Segment the spine into positions wrt the inputted linear distances\n",
        "- Test the functionality of code and debug\n",
        "- Send off the position, type and intensity of deviance in serial (e.g. serial.bwrite'{3},{STATIC},{HIGH}')\n",
        "- Debug and iterate with that (and record results with sensors)\n",
        "\n",
        "--------\n",
        "\n",
        "- Reducing the accumulation of noise:\n",
        "    - looking into methods of fixing the rotation issue (like with the issues in the forward kinematics algorithm) so that the resulting curves look like curves\n",
        "        - look into quaternions\n",
        "        - look into other approaches to this issue\n",
        "- Making the curve seem more spine-like:\n",
        "    - looking into biomechanics to inform my application of B-splines\n",
        "\n",
        "--------\n",
        "\n",
        "- Useability:\n",
        "    - Try to focus on the interface for this project (**in December, when every other part of the project is completely finished off**) so that I can prepare properly for the exhibition, where everyone can use the device (having gone through the calibration phase) and give feedback on the design, wearability and all that\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8X67a9KgTDv2",
      "metadata": {
        "id": "8X67a9KgTDv2"
      },
      "outputs": [],
      "source": [
        "import serial.tools.list_ports\n",
        "import string\n",
        "import serial\n",
        "import matplotlib.pyplot as plt\n",
        "from  mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "import scipy\n",
        "import sys # for debugging specifically"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd1e5f58",
      "metadata": {
        "id": "fd1e5f58"
      },
      "source": [
        "### Serial Reading & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AWEitd3jTJ4_",
      "metadata": {
        "id": "AWEitd3jTJ4_"
      },
      "outputs": [],
      "source": [
        "BAUDRATE = 115200\n",
        "try:\n",
        "    # setup for port communication\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    serialInst = serial.Serial()\n",
        "    portList = [str(i) for i in ports]\n",
        "    print(portList)\n",
        "\n",
        "    com = input(\"Select COM PORT for Arduino: \")\n",
        "\n",
        "    for i in range(len(portList)):\n",
        "        if portList[i].startswith(\"COM\" + str(com)):\n",
        "            SERIAL_PORT = \"COM\" + str(com)\n",
        "            print(SERIAL_PORT)\n",
        "\n",
        "    serialInst.baudrate = BAUDRATE\n",
        "    serialInst.port = SERIAL_PORT\n",
        "    serialInst.open()\n",
        "    print(f\"Connected to {SERIAL_PORT} at {BAUDRATE} baud.\")\n",
        "\n",
        "    '''\n",
        "    initial setup: 'begin program'\n",
        "    '''\n",
        "\n",
        "    while True:\n",
        "        line = serialInst.readline().decode('utf-8') #.strip()\n",
        "        if line: # if there is data in the readline\n",
        "            print(f\"Arduino: {line}\")\n",
        "        if \"Available channels:\" in line:\n",
        "            # extract all after the colon\n",
        "            channels_part = line.split(\":\")[-1].strip()\n",
        "            # parse the comma separated list into on stringed list\n",
        "            IMU_ID_LIST = [id.strip() for id in channels_part.split(\",\") if id.strip()]\n",
        "        if \"Number of sensors: \" in line:\n",
        "           ID_NUM = int(line.strip(\":\")[-3]) # the number of read sensors, last instance is \"\\n\" and so index = -3 is the appropriate index\n",
        "           #print(ID_NUM)\n",
        "           IMU_DEQUES = [deque(maxlen=50) for i in range(ID_NUM)]\n",
        "        if \"Waiting for 'begin program' command\" in line:\n",
        "            break\n",
        "\n",
        "    # get the linear distances for the forward kinematics calculation\n",
        "    print(\"INSTRUCTIONS:\\nInput the linear distances between your sensors in metres.\\nMeasure from lowest to highest.\\nI would recommend using a high resolution ruler to reduce drift.\\n\")\n",
        "    linear_distances = []\n",
        "    for i in range(ID_NUM - 1):\n",
        "        value = float(input(f\"{i + 1}: \"))\n",
        "        linear_distances.append(value)\n",
        "\n",
        "    print(\"Sending 'begin' command to Arduino\")\n",
        "    serialInst.write(b'begin program') # sent in bytes rather than high level strings\n",
        "                                       # since it is sent to the compiler\n",
        "\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc19e11",
      "metadata": {
        "id": "9dc19e11"
      },
      "source": [
        "### Functions & Algorithms\n",
        "I am here using a forward kinematics algorithm that inputs the matrix of accelerometer data (raw data?) and outputs a kinematic chain that approximates the scaled relationship between the sensors with the inputted linear distances.\n",
        "\n",
        "**Segmentation Algorithm**: The output of this is such that $[n_0, n_1, ..., n_i]$, where $0 < n < 1$ and $i$ is the length of the list. Using this format, $n_i \\equiv 1$ since it is a cumulative algorithm that indicates the percentiles in which these values should occur.\n",
        "\n",
        "Using this segmentation, I can then send data to the nearest haptic motor if a deviation has occurred.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8ad70a",
      "metadata": {
        "id": "4d8ad70a"
      },
      "outputs": [],
      "source": [
        "    def forward_kinematics(matrix, linear_distances):\n",
        "        '''\n",
        "        Computes positions using the IMU data and distances, assuming that the base IMU is at the origin.\n",
        "        Returns: list of 3D positions\n",
        "\n",
        "        For later improvements, I will use quaternions to handle the tilt as done in the CHARM Lab device.\n",
        "        '''\n",
        "\n",
        "        if not matrix:\n",
        "            return []\n",
        "\n",
        "        positions = [np.array([0,0,0])] # centre at the origin, the position vectors are arbitrary as long as they are scaled versions of reality\n",
        "        t_value_distance = [0]\n",
        "        cumulative_distance = 0\n",
        "\n",
        "        for i in range(1, len(matrix)):\n",
        "            # direction_vector is the difference in the vector direction of the sandwiched positions\n",
        "            direction_vector_i = np.array(matrix[i])\n",
        "            direction_vector_j = np.array(matrix[i-1])\n",
        "\n",
        "            direction_vector = direction_vector_i - direction_vector_j # relative direction\n",
        "            norm = np.linalg.norm(direction_vector)\n",
        "            if norm > 1e-10: # error handling incase it produces a small value (and handles for floating point error)\n",
        "                direction_vector = direction_vector / norm\n",
        "            else: # error handling\n",
        "                if i==1:\n",
        "                    direction_vector = np.array([0,0,1]) # simply translate the vector directly above it\n",
        "                else:\n",
        "                    # continue in the same direction as the previous linkage ()\n",
        "                    prev_pos = positions[-1] - positions[-2]\n",
        "                    direction_vector = prev_pos / np.linalg.norm(prev_pos)\n",
        "\n",
        "            distance = linear_distances[i-1]\n",
        "            link_vector = direction_vector * distance\n",
        "            new_pos = positions[-1] + link_vector # build from previous position\n",
        "            positions.append(new_pos)\n",
        "\n",
        "            cumulative_distance += distance\n",
        "            t_value_distance.append(cumulative_distance)\n",
        "\n",
        "        return positions, t_value_distance\n",
        "\n",
        "    def segmentation_algorithm(linear_distances_list):\n",
        "        array = np.array(linear_distances_list)\n",
        "        return np.cumsum(array) / np.sum(array)\n",
        "\n",
        "    def interquartile_mean_calculation(poor_posture_list_input):\n",
        "        list_input = np.array(poor_posture_list_input)\n",
        "        n = len(list_input)\n",
        "\n",
        "        if n == 0:\n",
        "            return np.nan # an empty list\n",
        "        if n < 4: # not enough elements for any meaningful IQR\n",
        "            return np.mean(list_input)\n",
        "\n",
        "        list_input.sort()\n",
        "        n_upper = int(n * 0.75)\n",
        "        n_lower = int(n * 0.25)\n",
        "\n",
        "        interquartile_list = list_input[n_lower:n_upper]\n",
        "\n",
        "        if interquartile_list.size == 0: # incase an unexpected error occurred\n",
        "            return np.mean(list_input)\n",
        "\n",
        "        interquartile_mean = np.mean(interquartile_list)\n",
        "        return interquartile_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19369b60",
      "metadata": {
        "id": "19369b60"
      },
      "source": [
        "### Databases & .csv Files\n",
        "It will be stored in a SQLite database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5f1d99",
      "metadata": {
        "id": "9b5f1d99"
      },
      "source": [
        "### Data Plotting\n",
        "\n",
        "The previous runs of this had a monolithic `animate(i)` function which made this impossible to debug.\n",
        "\n",
        "Therefore:\n",
        "- develop a class based structure\n",
        "- test this code in a separate file with pseudo data\n",
        "- there is an error with the runtime of this with 5 sensors\n",
        "\n",
        "All of these makes the implementation of ML (like `k-mean clustering` for the calibration phase) much harder to implement.\n",
        "\n",
        "There should also be ways of quantifying the improvements of this code but I am not sure currently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTOBgo0GSr3Q",
      "metadata": {
        "id": "FTOBgo0GSr3Q"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "I do not know how to implement the state variables across both classes in any meaningful way; this will be a problem that I will solve later.\n",
        "'''\n",
        "\n",
        "class Spine:\n",
        "    def __init__(self, raw_data, num_sensors):\n",
        "        '''\n",
        "        This holds the raw information of the digital twin except for any analysis.\n",
        "        The output of this is the function of the spine at a given point (and the list of its positions for previous timesteps) but nothing else.\n",
        "        Here there will be the storage into the database (SQLite) but I need to understand where this is actually stored and how to restore it after different runs of this code.\n",
        "        '''\n",
        "\n",
        "        self.raw_data = raw_data\n",
        "        self.num_sensors = num_sensors\n",
        "        self.poor_posture_start_time = None\n",
        "\n",
        "    def data_cleaning(self):\n",
        "        '''\n",
        "        Returns cleaned IMU data through whatever filter or combination of them to make sure that these vectors actually display tilt (and not something else)\n",
        "        '''\n",
        "        return self.clean_data\n",
        "\n",
        "    def interpolated_spline(self):\n",
        "        '''\n",
        "        This should also update the deque list (and how it is stored within the code)\n",
        "        Also have qualities such as 'self.position_vectors' and a specific understanding of how many vectors to have and where they all go handled nicely\n",
        "        '''\n",
        "        return self.interpolated_spline # just returns the spline with no further data\n",
        "\n",
        "    def database_storage(self):\n",
        "        '''\n",
        "        Call the database here and upload the raw data of the spine here and see the flaws in my recreation.\n",
        "        Raw data is the only important aspect here so this should be quite a simple endeavour.\n",
        "\n",
        "        The only issue here is the rate at which this function is called since there is now a real issue of threading and the rate of calling a function exceeding the rate it actually runs.\n",
        "        How do I overcome this?\n",
        "        '''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ylj8ymb9esSB",
      "metadata": {
        "id": "ylj8ymb9esSB"
      },
      "source": [
        "For the function `calibration_dataset(self)`, I am not sure whether this data should be raw or the already filtered curvatures from the `Spine` class. The filtered ones may be better since I could just improve the previous algorithm (using quaternions and filters to reduce the drift from the accelerometers) which would just save time.\n",
        "\n",
        "I also want to display this output as a nodal graph (and cluster the data in different colours for each of the IMU segments) to try to visualise what this intuitively means.\n",
        "\n",
        "For the function `calibrated_curvature(self)`, I am struggling to think of an appropriate output from this function given that I would have calculated the statistical distribution from the initial dataset but now what should I do with it. I want a method that is not computationally expensive (I don't want to calculate the range from which the data could fall into for each step). This will be a problem to solve, but I do not know when."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vGzVfq1vet7L",
      "metadata": {
        "id": "vGzVfq1vet7L"
      },
      "outputs": [],
      "source": [
        "class CurvatureAnalysis:\n",
        "    def __init__(self):\n",
        "        self.baseline_curvature = None\n",
        "        self.calibration_duration = 30\n",
        "        self.calibration_dataset = None\n",
        "\n",
        "    def calibration_dataset(self, spline):\n",
        "        '''\n",
        "        First creates the database called `sql-database-{random_seed}` # the random seed is such that I can have different instances of databses when I have different tests of this\n",
        "        This collects all the curvatures from the sensors during the calibration period into a dataset in which k-means clustering can take place.\n",
        "        '''\n",
        "        return self.calibration_dataset\n",
        "\n",
        "    def calibrated_curvature(self, spline):\n",
        "        '''\n",
        "        Using the dataset, k-means clustering will take place such that a measure of deviation from this distribution can be assertained.\n",
        "        My intention would be further for this data to be presented (not as a digital twin) to see whether more information can be ascertained.\n",
        "        What would be returned from this? The ranges of data this can fall between to not be an anomaly?\n",
        "        '''\n",
        "    def curvature_dataset_update(self, spline, tag):\n",
        "        # continue updating the same dataset from the calibration dataset but tag the data as `running` (or just not `calibrating` or deviating)\n",
        "        # these tags will inform the database writing\n",
        "\n",
        "    def curvature_deviance(self, spline):\n",
        "        '''\n",
        "        if Spine.interpolated_spline(spline) has not deviated from the above dataset:\n",
        "            store as `not deviated` (have a better name for this)\n",
        "            return None\n",
        "        else:\n",
        "            find where it has deviated (along the spline)\n",
        "            store this data (how could this graphically be represented) - send to a different function to store the data in the sqlite database\n",
        "            store as `deviated`\n",
        "            try to isolate the indices where this has occurred along the spline\n",
        "            call function that finds which IMU this should go to\n",
        "            return [red-indices-of-deviance], [haptic-motor-sensors-to-ignite]\n",
        "        '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to have a separate database class since the timings for updates for this will be different (and I also want the updates to the datbase to be at a higher frequency than the visualisation plot of the animate function).\n",
        "\n",
        "The file format is something similar to:\n",
        "``` python\n",
        "data = {\n",
        "    \"timestep\": timestep,\n",
        "    \"tag\": calibrating\n",
        "    \"IMU-raw-data\": IMU-raw-data # (1 x 3) matrix\n",
        "}\n",
        "```\n",
        "I would like to plot a graph of this (the points being the data points) and then having the timestep being the lower axis. This will help with the visualisation of this (befor the animation file for this).\n"
      ],
      "metadata": {
        "id": "DkVE1Sa8lmCM"
      },
      "id": "DkVE1Sa8lmCM"
    },
    {
      "cell_type": "code",
      "source": [
        "    class DatabaseLogger():\n",
        "        def __init__(self):\n",
        "            self.dbname = dbname\n",
        "\n"
      ],
      "metadata": {
        "id": "naKrxieSlSEE"
      },
      "id": "naKrxieSlSEE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the pseudocode for this, where I upload everything to a database nice and good to test the storage of this. Is this necessary?\n",
        "\n",
        "\n",
        "1. I will have distinct functions (not classes) that will help with the creation of the spline object in real time without a class. These functions will:\n",
        "\n",
        "    - clean the IMU data\n",
        "\n",
        "    - produce an appropriate interpolation of this data (that will be outputted in similar formats such that it is modular, whether it be a vector of length n that is consistent regardless of how I improve the functions with increasingly complex quaternion math or madgwick filtering)\n",
        "\n",
        "2. Now there will be a class that handles the stored interpreted data which needs the states of timings for the the different points( poor_posture_time, `calibration_duration`) as well as storing the local state of what the calibration function (or how to cluster the data points during this calibration time, I am thinking of k-means clustering and then defining a standard deviation for this (if there is a sharp change in curvature for a short period time that isn't noise) as well as a function that alterts the user if there has been posture that is prolonged within this frame (i.e. just sitting static in front of a screen for a while without any movement))\n",
        "\n",
        "3. This then runs within the animate function but has been sectioned off to the different classes and functions and also towards the visualisation of the code"
      ],
      "metadata": {
        "id": "pZhe4L0VoBZp"
      },
      "id": "pZhe4L0VoBZp"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-1RVqI-oA4N"
      },
      "id": "T-1RVqI-oA4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Setup"
      ],
      "metadata": {
        "id": "w8amna5lgyMu"
      },
      "id": "w8amna5lgyMu"
    },
    {
      "cell_type": "code",
      "source": [
        "    fig = plt.figure(figsize=(15,9))\n",
        "    ax = fig.add_subplot(121, projection='3d')\n",
        "    ax2 = fig.add_subplot(122)\n",
        "\n",
        "    ## set the points for the animate(i) function\n",
        "    ## these variables are what are updated (and saves clearing the plot each time)\n",
        "    scatter = ax.scatter([], [], [], s=50)\n",
        "    line, = ax.plot([], [], [])\n",
        "    scatter_hotspot = ax.scatter([], [], [], color='red', s=50)\n",
        "\n",
        "    ax.set_title(\"IMU Positions\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_zlabel(\"Z (m)\")"
      ],
      "metadata": {
        "id": "peLnzqT8gxja"
      },
      "id": "peLnzqT8gxja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the rewritten function in its entirety, where each section is run and the class-based system allows debugging to occur at a much more efficient rate."
      ],
      "metadata": {
        "id": "gyFV_2DVbbod"
      },
      "id": "gyFV_2DVbbod"
    },
    {
      "cell_type": "code",
      "source": [
        "    def animate(i):\n",
        "        try:\n",
        "            '''\n",
        "            1. Input and clean up the data from the IMU & sort out the channels of this so that the deques are running correctly\n",
        "            2. Make the interpolated spline & curvature analysis instance\n",
        "            3. Instructions that a calibration phase will take place and to get the user in a good position\n",
        "            4. Calibration phase (with all the data at this point being inputted into the sql-database)\n",
        "            5. The code running as normal; if a deviation (how is this defined) then the data is sent through the compiler otherwise just...\n",
        "            6. Render the plot of:\n",
        "                a. the interpolated spline function (the 'digital-twin')\n",
        "                b. the k-means cluster (or way of approaching this problem)\n",
        "            '''\n",
        "        except Exception as e:\n",
        "            print(f'Serial line error: {e}')\n",
        "            return # plotting stuff"
      ],
      "metadata": {
        "id": "w1-lqXzcbbHf"
      },
      "id": "w1-lqXzcbbHf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D6wfY78DTgnE",
      "metadata": {
        "id": "D6wfY78DTgnE"
      },
      "outputs": [],
      "source": [
        "\n",
        "    baseline_curvature = None\n",
        "    is_calibrating = True\n",
        "    calibration_start_time = time.time()\n",
        "    calibration_duration = 3 # seconds; increase this time for actual deployment. It will be low for testing.\n",
        "    calibration_curvature_array = [] # use np.array or something similar\n",
        "    calibration_standard_deviation = [] # standard deviation of the points on the thing\n",
        "\n",
        "    poor_posture_list = [] # contains the arrays of all the deviated postures\n",
        "    poor_posture_start_time = None # storing the time.time() when poor posture starts\n",
        "    threshold_time = 0.1 # seconds; it will increase again after testing\n",
        "\n",
        "    plot_radius = sum(linear_distances) * 1.125 # a scaled form of the plot so that I can see the results more clearly\n",
        "\n",
        "    linear_distance_percentiles = segmentation_algorithm(linear_distances) # positions of the linear distance percentiles\n",
        "    print(f\"\\nCALIBRATION PHASE.\\nDURATION: {calibration_duration}\\n\\n\")\n",
        "    def animate(i):\n",
        "        # making these values global in this function will reduce the chance of errors\n",
        "        global baseline_curvature, is_calibrating, calibration_start_time, calibration_curvature_array\n",
        "        global curvature_standard_deviation, poor_posture_list, poor_posture_start_time\n",
        "\n",
        "        try:\n",
        "            \"\"\"DATA ACQUISITION\"\"\"\n",
        "            IMU_FULL_CHANNEL_DATA = serialInst.readline().decode('utf-8').strip().split(\",\")\n",
        "            IMU_ID = int(IMU_FULL_CHANNEL_DATA[-1]) # the ID prescribed by the sensor number\n",
        "            IMU_DATA = [float(acc) for acc in IMU_FULL_CHANNEL_DATA[:3]] # ONLY APPENDING ACCELERATION, TO CHANGE WHEN DOING KALMAN FILTERING\n",
        "            IMU_DATA_NORM = IMU_DATA/np.linalg.norm(IMU_DATA)\n",
        "\n",
        "            try:\n",
        "                target_IMU_index = IMU_ID_LIST.index(str(IMU_ID)) # str(IMU_ID) since IMU_ID_LIST is a string\n",
        "                IMU_DEQUES[target_IMU_index].append(IMU_DATA_NORM)\n",
        "\n",
        "            except ValueError:\n",
        "                print(f\"Warning: Recieved data from unknown data channel @ ID:{IMU_ID}\")\n",
        "\n",
        "            if all(IMU_DEQUES):# when there is data in all of the deques i.e. all the sensors are outputting data\n",
        "                IMU_NORMALISED_MATRIX = [dque[-1] for dque in IMU_DEQUES]\n",
        "                positions, t_values = forward_kinematics(IMU_NORMALISED_MATRIX)\n",
        "                IMU_POSITIONS = np.array(positions)\n",
        "\n",
        "                x = IMU_POSITIONS[:, 0]\n",
        "                y = IMU_POSITIONS[:, 1]\n",
        "                z = IMU_POSITIONS[:, 2]\n",
        "\n",
        "                # below is an example of a global cubic spline which will be easier to compute.\n",
        "                # I will experiment later with other forms of parametric equations (e.g. constrained b-splines) but the simplicity of this will help with better optimisation\n",
        "                xc = CubicSpline(t_values, x)\n",
        "                yc = CubicSpline(t_values, y)\n",
        "                zc = CubicSpline(t_values, z)\n",
        "\n",
        "                plot_t = np.linspace(min(t_values), max(t_values), 250) # t_values to for a smooth plot\n",
        "\n",
        "                curvature_list = [] # the list for values of $\\kappa$ that updates for each instance of the spline curve\n",
        "                for i in range(len(plot_t)):\n",
        "                    r = (xc(plot_t[i], 0), yc(plot_t[i], 0), zc(plot_t[i], 0))\n",
        "                    r_prime = (xc(plot_t[i], 1), yc(plot_t[i], 1), zc(plot_t[i], 1))\n",
        "                    r_double_prime = (xc(plot_t[i], 2), yc(plot_t[i], 2), zc(plot_t[i], 2))\n",
        "\n",
        "                    kappa = (np.linalg.norm(np.cross(r_prime, r_double_prime)))/(np.linalg.norm(r_prime)**3)\n",
        "                    curvature_list.append(kappa)\n",
        "\n",
        "                curvature_instance_array = np.array(curvature_list)\n",
        "\n",
        "                # Now I will apply the state conditions\n",
        "                \"\"\"CALIBRATION PHASE\"\"\"\n",
        "                if is_calibrating is True:\n",
        "                    # collect data through the list quantity outside of the loop\n",
        "                    calibration_curvature_array.append(curvature_instance_array)\n",
        "                    if (time.time() - calibration_start_time) > calibration_duration:\n",
        "                        # do the processing: simple test will just include the mean of the results but later ones will research into other methods\n",
        "                        # like using a mix between the standard deviation, rolling mean\n",
        "                        \"\"\"\n",
        "                        For future models, I will have the calibration phase be where the user moves to (a) a comfortable posititon, (b) defined positions that would be displayed (such as asking the user to tilt forward (there will be a diagam of what to do))\n",
        "                        From this, I can develop an ML model (or just do more research into anatomical landmarks) and have a personalised \"shape\" for the user's spine; even if they have spinal deformities -- given the amount of input data from this calibration phase.\n",
        "                        Then other forms of means can be applied (to be )\n",
        "                        \"\"\"\n",
        "                        # mean value stored over this timestep (which doesn't actually need to be defined)\n",
        "                        baseline_curvature = np.mean(calibration_curvature_array, axis=0)\n",
        "\n",
        "                        # define the standard deviation of this distribution\n",
        "                        curvature_standard_deviation = np.std(calibration_curvature_array, axis=0)\n",
        "\n",
        "                        # leave this state\n",
        "                        print(\"\\nNOW EXITING CALIBRATION PHASE\\n\\n\")\n",
        "                        is_calibrating = False\n",
        "                else:\n",
        "                    # begin the monitoring mode\n",
        "                    # compare the calibration code things, checking if the difference is within the standard deviation of each of the curvatures\n",
        "                    if any((curvature_instance_array - baseline_curvature) > 1.5 * curvature_standard_deviation): # if there is a single instance of a deviation\n",
        "                        \"\"\"Poor posture has started. Start storing the indices of where the deviances have occurred and use this for later plotting.\"\"\"\n",
        "                        \"\"\"The positions will also say where a signal should be sent along the spine\"\"\"\n",
        "\n",
        "                        \"\"\"\n",
        "                        list structure that is 0 unless at the indicies where the baseline_curvature has exceeded\n",
        "                        Then it will show by how much it has exceeded this level (the difference)\n",
        "                        e.g. np.array([0,0,0,0,1,1.2,1.9,2.1,1.1,0.75,0.5,0,0,0,0,0])\n",
        "                        It must retain the total length of the curvature_instance_array (as this index will be important)\n",
        "                        \"\"\"\n",
        "\n",
        "                        print(\"THERE HAS BEEN DETECTED POOR POSTURE.\")\n",
        "                        deviation = (curvature_instance_array - baseline_curvature)\n",
        "                        deviated_posture_instance = np.where((deviation > 1.5 * curvature_standard_deviation), deviation, 0)\n",
        "\n",
        "                        poor_posture_list.append(deviated_posture_instance)\n",
        "\n",
        "                        if poor_posture_start_time == None:\n",
        "                            poor_posture_start_time = time.time()\n",
        "\n",
        "\n",
        "                        elif (time.time() - poor_posture_start_time) > threshold_time:\n",
        "                            \"\"\"\n",
        "                            There is now sustained poor posture, therefore model a distribution of the deviances of the posture. Depending on the threshold time, I could include a recency bias.\n",
        "                            Send a signal to serial indicating the position of this poor posture and where the average of this is.\n",
        "                            The signal processing (a dedicated function for ease) will send out:\n",
        "                                1. The sensor(s) which is/are nearest to the deviations\n",
        "                                2. The intensity of the haptic motor signal (from the distribution of peaks (should use deques for this aspect with the recency bias))\n",
        "                                3. Tackle the issue of n-number deviances\n",
        "                                4. Share this to the serial in this format: \"serial.write(bf'Curve, {signal_response[0]}, {signal_response[1]}')\"\n",
        "                                5. Use the indices to plot the points in 3D space\n",
        "                            \"\"\"\n",
        "                            poor_posture_list_numpy = np.array(poor_posture_list)\n",
        "                            average_deviated_posture = np.array([interquartile_mean_calculation(poor_posture_list_numpy[:,i]) for i in range(len(poor_posture_list_numpy[0]))]) # i.e. for i in range({the length of each of the lists})\n",
        "\n",
        "                            \"\"\"\n",
        "                            With this initial test, I will find the local maxima for the interpolated graph (using cubic interpolation; but will have this graph displayed for debugging)\n",
        "                            \"\"\"\n",
        "                            deviated_graph_range = average_deviated_posture - baseline_curvature\n",
        "                            \"\"\"\n",
        "                            # This may produce errors since the length of this list does not equate the thing that I will index it against\n",
        "                            deviated_graph_domain = np.arange(len(deviated_graph_range))\n",
        "\n",
        "                            # interpolate this into a function\n",
        "                            deviated_graph_function = CubicSpline(deviated_graph_domain, deviated_graph_range)\n",
        "\n",
        "                            # find the local maximum (and its index) for this\n",
        "\n",
        "                            deviated_graph_domain_refined = np.linspace(0, len(deviated_graph_range), (len(deviated_graph_range) * 5)) # refined to approach the dx of finding the derivatives anyways\n",
        "                            deviated_graph_range_refined = deviated_graph_function(deviated_graph_domain_refined)\n",
        "                            \"\"\"\n",
        "                            peak_indices, dictionary_properties = scipy.signal.find_peaks(deviated_graph_range, prominence=None) # adjust the prominence values throughout through the test\n",
        "                            # this can then be used to plot the position of the deviaiton (as a hotspot on the thing)\n",
        "                            \"\"\"\n",
        "                            These indices are now the same for my hotspot which can be plotted as positions (which is fun and cool)\n",
        "                            \"\"\"\n",
        "                            ## later, break down the fucntion into the points of the linear distances and get that all sorted out\n",
        "                            \"\"\"\n",
        "                            Finding the linear distance thing is easy since I can just use the ratios between the distances and find the indices of them\n",
        "                            Once I have done this bit I am free since I can print it out a red dot for where the deviation is and then be free\n",
        "                            the place of the sensor can then be outputted from it\n",
        "                            \"\"\"\n",
        "                            peak_incides_percentile = peak_indices / len(deviated_graph_range)\n",
        "                            sensor_indices = []\n",
        "\n",
        "                            for each_index in peak_incides_percentile:\n",
        "                                # the argument where min(each_index - linear_distance_percentiles), i.e. the index in linear_distance_percentiles that this happens (because this is then the sensor that this happens in )\n",
        "                                dist = np.abs(linear_distance_percentiles - each_index)\n",
        "                                sensor_index = dist.argmin()\n",
        "                                sensor_indices.append(sensor_index)\n",
        "\n",
        "                            serialInst.write(f'DEVIATED_CURVE, {str(sensor_indices)}, [INTENSITY_VALUE]'.encode()) # there have been errors with the output of the sensor_indices not being a string\n",
        "\n",
        "                            scatter_hotspot._offsets3d = (xc(plot_t[peak_indices]), yc(plot_t[peak_indices]), zc(plot_t[peak_indices]))\n",
        "                            # the output to the serial will be a numpy array\n",
        "\n",
        "                            return scatter, line, scatter_hotspot\n",
        "\n",
        "                    else:\n",
        "                        '''GOOD POSTURE'''\n",
        "                        poor_posture_list = []\n",
        "                        poor_posture_start_time = None\n",
        "                        scatter_hotspot._offsets3d = ([], [], [])\n",
        "\n",
        "                \"\"\"PLOTTING LOGIC\"\"\"\n",
        "                # Logic to allow the spline to be centred in frame (for easy visibility)\n",
        "                centre_point = np.mean(IMU_POSITIONS, axis=0) # axis=0 is working along the column, axis=1 works along rows (especially with bigger matrices)\n",
        "\n",
        "                ax.set_xlim(centre_point[0] - plot_radius, centre_point[0] + plot_radius)\n",
        "                ax.set_ylim(centre_point[1] - plot_radius, centre_point[1] + plot_radius)\n",
        "                ax.set_zlim(centre_point[2] - plot_radius, centre_point[2] + plot_radius)\n",
        "\n",
        "                ## update stored variables (\"scatter\" + \"line,\") with new positions\n",
        "                ## more efficient than ax.clear()\n",
        "\n",
        "                scatter._offsets3d = (IMU_POSITIONS[:, 0], IMU_POSITIONS[:, 1], IMU_POSITIONS[:, 2]) # plots all x, y, z coordinates: regardless of number of rows in this matrix\n",
        "\n",
        "                \"\"\"\n",
        "                Now plot the position\n",
        "                \"\"\"\n",
        "                # line.set_data(IMU_POSITIONS[:, :2].T) # takes in (x,y) values of the points (matplotlib used to only do 2D stuff)\n",
        "                # line.set_3d_properties(IMU_POSITIONS[:, 2]) # add the z-coordinate (3D space) on top of this\n",
        "\n",
        "                line.set_data(xc(plot_t), yc(plot_t))\n",
        "                line.set_3d_properties(zc(plot_t))\n",
        "                ax.grid()\n",
        "\n",
        "                ax2.clear()\n",
        "                ax2.plot(plot_t, curvature_list)\n",
        "                # print(max(curvature_list))\n",
        "                # print(f\"Current Avg: {np.mean(curvature_list)}\")\n",
        "                ax2.set_title(\"Curvature Graph\")\n",
        "                ax2.grid()\n",
        "\n",
        "                \"\"\"CALL THE .CSV FUNCTION/SQLITE DATA HERE TO STORE ALL THE DATA IN THE WAY THAT IS NECESSARY\"\"\"\n",
        "\n",
        "        except (ValueError, IndexError) as e:\n",
        "            print(f\"Serial line error: {e}\")\n",
        "            # pass\n",
        "            return scatter, line, scatter_hotspot\n",
        "\n",
        "        return scatter, line, scatter_hotspot\n",
        "\n",
        "    # PLOTTING DISPLAY\n",
        "    anim = FuncAnimation(fig, animate, cache_frame_data=False, interval=100, blit=True) # blitting only draws the dynamic aspects of the plot\n",
        "                                                                                        # rather than redrawing e.g. '{Title}' at each timestep\n",
        "                                                                                        # this save computation\n",
        "    ax.set_box_aspect([1,1,1])\n",
        "    ax.set_proj_type('ortho')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e8db39a",
      "metadata": {
        "id": "8e8db39a"
      },
      "source": [
        "### Exceptions\n",
        "Although quite simple, this has helped to quickly identify bugs in the code and solve them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34498c15",
      "metadata": {
        "id": "34498c15"
      },
      "outputs": [],
      "source": [
        "except Exception as e:\n",
        "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
        "            line_number = exc_traceback.tb_lineno\n",
        "                print(f\"ERROR: {e}, line {line_number}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}